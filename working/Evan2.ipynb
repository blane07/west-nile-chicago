{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Original code: Beating the Benchmark from West Nile Virus Prediction @ Kaggle by Abhihsek. Modified by Brendan Lane*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$('.nbp-app-bar').toggle()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$('.nbp-app-bar').toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset \n",
    "train = pd.read_csv('../assets/train.csv')\n",
    "test = pd.read_csv('../assets/test.csv')\n",
    "sample = pd.read_csv('../assets/sampleSubmission.csv')\n",
    "weather = pd.read_csv('../assets/weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using codesum for this benchmark\n",
    "weather.drop('CodeSum', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split station 1 and 2 and join horizontally\n",
    "weather_stn1 = weather[weather['Station']==1]\n",
    "weather_stn2 = weather[weather['Station']==2]\n",
    "weather_stn1 = weather_stn1.drop('Station', axis=1)\n",
    "weather_stn2 = weather_stn2.drop('Station', axis=1)\n",
    "weather = weather_stn1.merge(weather_stn2, on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace some missing values and T with -1\n",
    "weather = weather.replace('M', -1)\n",
    "weather = weather.replace('-', -1)\n",
    "weather = weather.replace('T', -1)\n",
    "weather = weather.replace(' T', -1)\n",
    "weather = weather.replace('  T', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to extract month and day from dataset\n",
    "# You can also use parse_dates of Pandas.\n",
    "def create_year(x):\n",
    "    return x.split('-')[0]\n",
    "def create_month(x):\n",
    "    return x.split('-')[1]\n",
    "def create_day(x):\n",
    "    return x.split('-')[2]\n",
    "\n",
    "train['month'] = train.Date.apply(create_month)\n",
    "train['day'] = train.Date.apply(create_day)\n",
    "train['year'] = train.Date.apply(create_year)\n",
    "\n",
    "test['month'] = test.Date.apply(create_month)\n",
    "test['day'] = test.Date.apply(create_day)\n",
    "test['year'] = test.Date.apply(create_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop address columns\n",
    "train = train.drop(['Address', 'AddressNumberAndStreet'], axis = 1)\n",
    "test = test.drop(['Id', 'Address', 'AddressNumberAndStreet'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with weather data\n",
    "train = train.merge(weather, on='Date')\n",
    "test = test.merge(weather, on='Date')\n",
    "train = train.drop(['Date'], axis = 1)\n",
    "test = test.drop(['Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numbers\n",
    "lbl = LabelEncoder()\n",
    "lbl.fit(list(train['Species'].values) + list(test['Species'].values))\n",
    "train['Species'] = lbl.transform(train['Species'].values)\n",
    "test['Species'] = lbl.transform(test['Species'].values)\n",
    "\n",
    "lbl.fit(list(train['Street'].values) + list(test['Street'].values))\n",
    "train['Street'] = lbl.transform(train['Street'].values)\n",
    "test['Street'] = lbl.transform(test['Street'].values)\n",
    "\n",
    "lbl.fit(list(train['Trap'].values) + list(test['Trap'].values))\n",
    "train['Trap'] = lbl.transform(train['Trap'].values)\n",
    "test['Trap'] = lbl.transform(test['Trap'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with -1s\n",
    "train = train.loc[:,(train != -1).any(axis=0)]\n",
    "test = test.loc[:,(test != -1).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert all data types to floats\n",
    "train = train.astype(float)\n",
    "test = test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature engineering\n",
    "# Temperature difference\n",
    "train['temp_delta_x'] = train.Tmax_x - train.Tmin_x\n",
    "train['temp_delta_y'] = train.Tmax_y - train.Tmin_y\n",
    "train['temp_delta_x'] = train.Tmax_x - train.Tmin_x\n",
    "train['temp_delta_y'] = train.Tmax_y - train.Tmin_y\n",
    "test['temp_delta_x'] = test.Tmax_x - test.Tmin_x\n",
    "test['temp_delta_y'] = test.Tmax_y - test.Tmin_y\n",
    "test['temp_delta_x'] = test.Tmax_x - test.Tmin_x\n",
    "test['temp_delta_y'] = test.Tmax_y - test.Tmin_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is raining?\n",
    "train['israining_x'] = (train.PrecipTotal_x > 0).astype(int)\n",
    "train['israining_y'] = (train.PrecipTotal_y > 0).astype(int)\n",
    "test['israining_x'] = (test.PrecipTotal_x > 0).astype(int)\n",
    "test['israining_y'] = (test.PrecipTotal_y > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of sunlight\n",
    "train['sunlight'] = train.Sunset_x - train.Sunrise_x\n",
    "test['sunlight'] = test.Sunset_x - test.Sunrise_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace outliers with median value\n",
    "train.WetBulb_x = train.WetBulb_x.apply(lambda x: train.WetBulb_x.median() if x < 0 else x)\n",
    "test.WetBulb_x = test.WetBulb_x.apply(lambda x: test.WetBulb_x.median() if x < 0 else x)\n",
    "\n",
    "train.StnPressure_x = train.StnPressure_x.apply(lambda x: train.StnPressure_x.median() if x < 0 else x)\n",
    "test.StnPressure_x = test.StnPressure_x.apply(lambda x: test.StnPressure_x.median() if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative humidity approximation\n",
    "train['RH'] = 100 - (25 / 9) * (train.Tavg_x - train.DewPoint_x)\n",
    "test['RH'] = 100 - (25 / 9) * (test.Tavg_x - test.DewPoint_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is heat wave?\n",
    "train['isheat'] = (train.Heat_x > 0).astype(float)\n",
    "test['isheat'] = (test.Heat_x > 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize resultant wind into north and east components\n",
    "wind_dir_north_x = train.ResultDir_x.apply(lambda x: np.sin(np.deg2rad(x)))\n",
    "wind_dir_east_x = train.ResultDir_x.apply(lambda x: np.cos(np.deg2rad(x)))\n",
    "train['wind_north_x'] = wind_dir_north_x * train.ResultSpeed_x\n",
    "train['wind_east_x'] = wind_dir_east_x * train.ResultSpeed_x\n",
    "\n",
    "wind_dir_north_y = train.ResultDir_y.apply(lambda x: np.sin(np.deg2rad(x)))\n",
    "wind_dir_east_y = train.ResultDir_y.apply(lambda x: np.cos(np.deg2rad(x)))\n",
    "train['wind_north_y'] = wind_dir_north_y * train.ResultSpeed_y\n",
    "train['wind_east_y'] = wind_dir_east_y * train.ResultSpeed_y\n",
    "\n",
    "wind_dir_north_x = test.ResultDir_x.apply(lambda x: np.sin(np.deg2rad(x)))\n",
    "wind_dir_east_x = test.ResultDir_x.apply(lambda x: np.cos(np.deg2rad(x)))\n",
    "test['wind_north_x'] = wind_dir_north_x * test.ResultSpeed_x\n",
    "test['wind_east_x'] = wind_dir_east_x * test.ResultSpeed_x\n",
    "\n",
    "wind_dir_north_y = test.ResultDir_y.apply(lambda x: np.sin(np.deg2rad(x)))\n",
    "wind_dir_east_y = test.ResultDir_y.apply(lambda x: np.cos(np.deg2rad(x)))\n",
    "test['wind_north_y'] = wind_dir_north_y * test.ResultSpeed_y\n",
    "test['wind_east_y'] = wind_dir_east_y * test.ResultSpeed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize average wind into north and east components\n",
    "train['avg_wind_north_x'] = wind_dir_north_x * train.AvgSpeed_x\n",
    "train['avg_wind_east_x'] = wind_dir_east_x * train.AvgSpeed_x\n",
    "\n",
    "train['avg_wind_north_y'] = wind_dir_north_y * train.AvgSpeed_y\n",
    "train['avg_wind_east_y'] = wind_dir_east_y * train.AvgSpeed_y\n",
    "\n",
    "test['avg_wind_north_x'] = wind_dir_north_x * test.AvgSpeed_x\n",
    "test['avg_wind_east_x'] = wind_dir_east_x * test.AvgSpeed_x\n",
    "\n",
    "test['avg_wind_north_y'] = wind_dir_north_y * test.AvgSpeed_y\n",
    "test['avg_wind_east_y'] = wind_dir_east_y * test.AvgSpeed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([train.reset_index(), (pd.get_dummies(train.year)).reset_index(), (pd.get_dummies(train.month)).reset_index(), (pd.get_dummies(train.Species)).reset_index()], axis='columns')\n",
    "# test = pd.concat([test.reset_index(), (pd.get_dummies(test.year)).reset_index(), (pd.get_dummies(test.month)).reset_index(), (pd.get_dummies(test.Species)).reset_index()], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['Species'], drop_first=True)\n",
    "test = pd.get_dummies(test, columns=['Species'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['PrecipTotal_x', 'PrecipTotal_y', 'Sunrise_x', 'Sunset_x',\n",
    "             'Heat_x', 'Depth_x', 'SnowFall_x', 'ResultDir_x', 'ResultSpeed_x',\n",
    "             'ResultDir_y', 'ResultSpeed_y', 'AvgSpeed_x', 'AvgSpeed_y', 'year',\n",
    "             'month', 'day']\n",
    "\n",
    "train.drop(drop_list + ['NumMosquitos'], axis='columns', inplace=True)\n",
    "test.drop(drop_list + ['Species_7.0'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dependent (y) and indepedent (X) variables\n",
    "y = train.WnvPresent\n",
    "X = train.drop('WnvPresent', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475537787930707"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline accuracy\n",
    "1 - y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale X for modeling\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475250626167533"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest\n",
    "cross_val_score(RandomForestClassifier(max_depth=4, max_features=5), X_train, y_train,\n",
    "                cv=5, n_jobs=-1, verbose=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Doesn't break baseline. What is happening?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1992,    0],\n",
       "       [ 110,    0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confustion matrix\n",
    "clf = RandomForestClassifier(max_depth=4, max_features=5)\n",
    "clf.fit(X_train, y_train)\n",
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The model is maximizing accuracy by predicting \"No\" everytime. This is the result of have unbalanced classes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampled train/test split\n",
    "yo = train.WnvPresent.values\n",
    "Xo = train\n",
    "X_traino, X_testo, y_traino, y_testo = train_test_split(Xo, yo, test_size=0.2, stratify=yo)\n",
    "X_traino = pd.DataFrame(scaler.fit_transform(X_traino), columns=X_traino.columns)\n",
    "X_testo = pd.DataFrame(scaler.fit_transform(X_testo), columns=X_testo.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe of positive West Nile results\n",
    "pos_train = X_traino[X_traino.WnvPresent > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampled unrepresented class\n",
    "l = pos_train.shape[0]\n",
    "X_traino = pd.concat([X_traino, pos_train], axis=0)\n",
    "for _ in range(10):\n",
    "    X_traino = pd.concat([X_traino, pos_train], axis=0)\n",
    "y_traino = X_traino.WnvPresent.values\n",
    "y_traino = np.array([1 * (x > 0) for x in y_traino])\n",
    "X_traino = X_traino.drop('WnvPresent', axis='columns')\n",
    "X_testo = X_testo.drop('WnvPresent', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12814\n",
      "12814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_traino.shape[0] - l)\n",
    "print(y_traino.shape[0] - l)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_traino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to maximize recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1628  364]\n",
      " [  39   71]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.82      0.89      1992\n",
      "        Yes       0.16      0.65      0.26       110\n",
      "\n",
      "avg / total       0.93      0.81      0.86      2102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=4, max_features=7)\n",
    "clf.fit(X_traino, y_traino)\n",
    "print(confusion_matrix(y_testo, clf.predict(X_testo)))\n",
    "print(classification_report(y_testo, clf.predict(X_testo), target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8103368017524644"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_testo, clf.predict_proba(X_testo)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7849666983824929"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_traino, y_traino)\n",
    "logreg.score(X_testo, y_testo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8017091091639283"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_testo, logreg.predict_proba(X_testo)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6078587075575027\n",
      "0.6354098211025923\n",
      "0.6626551661190215\n",
      "0.6872261774370209\n",
      "0.6933598028477547\n",
      "0.6977774735304857\n",
      "0.7073156261409274\n",
      "0.7253719423147135\n",
      "0.7342141292442498\n",
      "0.7395376962395034\n",
      "0.7379586527929901\n",
      "0.7376985213581599\n",
      "0.7398525921869297\n",
      "0.7390014603870025\n",
      "0.7393049470609712\n",
      "0.7416689485213582\n",
      "0.7450848849945235\n",
      "0.7486902154070829\n",
      "0.749977181453085\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 20):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_traino, y_traino)\n",
    "    print(roc_auc_score(y_testo, knn.predict_proba(X_testo)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1578,  414],\n",
       "       [  38,   72]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_testo, logreg.predict(X_testo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_units = X_train.shape[1]\n",
    "hidden_units = input_units\n",
    "\n",
    "model.add(Dense(hidden_units * 2,\n",
    "                input_dim=input_units,\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(hidden_units * 2,\n",
    "                input_dim=input_units,\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10,\n",
    "                input_dim=input_units,\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13255 samples, validate on 2102 samples\n",
      "Epoch 1/100\n",
      "13255/13255 [==============================] - 2s 121us/step - loss: 0.5674 - acc: 0.6939 - val_loss: 0.3836 - val_acc: 0.8268\n",
      "Epoch 2/100\n",
      "13255/13255 [==============================] - 1s 61us/step - loss: 0.4895 - acc: 0.7578 - val_loss: 0.4107 - val_acc: 0.7878\n",
      "Epoch 3/100\n",
      "13255/13255 [==============================] - 1s 60us/step - loss: 0.4586 - acc: 0.7719 - val_loss: 0.4005 - val_acc: 0.7788\n",
      "Epoch 4/100\n",
      "13255/13255 [==============================] - 1s 72us/step - loss: 0.4389 - acc: 0.7783 - val_loss: 0.3772 - val_acc: 0.7778\n",
      "Epoch 5/100\n",
      "13255/13255 [==============================] - 1s 77us/step - loss: 0.4260 - acc: 0.7891 - val_loss: 0.3381 - val_acc: 0.7897\n",
      "Epoch 6/100\n",
      "13255/13255 [==============================] - 1s 77us/step - loss: 0.4147 - acc: 0.7923 - val_loss: 0.3513 - val_acc: 0.7783\n",
      "Epoch 7/100\n",
      "13255/13255 [==============================] - 1s 80us/step - loss: 0.4017 - acc: 0.8044 - val_loss: 0.3821 - val_acc: 0.7531\n",
      "Epoch 8/100\n",
      "13255/13255 [==============================] - 1s 76us/step - loss: 0.3888 - acc: 0.8101 - val_loss: 0.3423 - val_acc: 0.7778\n",
      "Epoch 9/100\n",
      "13255/13255 [==============================] - 1s 83us/step - loss: 0.3858 - acc: 0.8107 - val_loss: 0.3551 - val_acc: 0.7759\n",
      "Epoch 10/100\n",
      "13255/13255 [==============================] - 1s 105us/step - loss: 0.3720 - acc: 0.8180 - val_loss: 0.3834 - val_acc: 0.7479\n",
      "Epoch 11/100\n",
      "13255/13255 [==============================] - 1s 62us/step - loss: 0.3645 - acc: 0.8241 - val_loss: 0.3675 - val_acc: 0.7564\n",
      "Epoch 12/100\n",
      "13255/13255 [==============================] - 1s 58us/step - loss: 0.3618 - acc: 0.8275 - val_loss: 0.3403 - val_acc: 0.7726\n",
      "Epoch 13/100\n",
      "13255/13255 [==============================] - 1s 58us/step - loss: 0.3524 - acc: 0.8346 - val_loss: 0.3669 - val_acc: 0.7731\n",
      "Epoch 14/100\n",
      "13255/13255 [==============================] - 1s 60us/step - loss: 0.3396 - acc: 0.8387 - val_loss: 0.3664 - val_acc: 0.7650\n",
      "Epoch 15/100\n",
      "13255/13255 [==============================] - 1s 77us/step - loss: 0.3408 - acc: 0.8389 - val_loss: 0.3495 - val_acc: 0.7926\n",
      "Epoch 16/100\n",
      "13255/13255 [==============================] - 1s 91us/step - loss: 0.3358 - acc: 0.8439 - val_loss: 0.3523 - val_acc: 0.7883\n",
      "Epoch 17/100\n",
      "13255/13255 [==============================] - 1s 89us/step - loss: 0.3278 - acc: 0.8469 - val_loss: 0.3649 - val_acc: 0.7888\n",
      "Epoch 18/100\n",
      "13255/13255 [==============================] - 1s 86us/step - loss: 0.3241 - acc: 0.8514 - val_loss: 0.3773 - val_acc: 0.7869\n",
      "Epoch 19/100\n",
      "13255/13255 [==============================] - 1s 91us/step - loss: 0.3235 - acc: 0.8530 - val_loss: 0.3530 - val_acc: 0.8021\n",
      "Epoch 20/100\n",
      "13255/13255 [==============================] - 1s 89us/step - loss: 0.3179 - acc: 0.8550 - val_loss: 0.3414 - val_acc: 0.8002\n",
      "Epoch 21/100\n",
      "13255/13255 [==============================] - 1s 77us/step - loss: 0.3121 - acc: 0.8567 - val_loss: 0.3659 - val_acc: 0.7969\n",
      "Epoch 22/100\n",
      "13255/13255 [==============================] - 1s 82us/step - loss: 0.3100 - acc: 0.8605 - val_loss: 0.3494 - val_acc: 0.7969\n",
      "Epoch 23/100\n",
      "13255/13255 [==============================] - 1s 58us/step - loss: 0.3053 - acc: 0.8644 - val_loss: 0.3594 - val_acc: 0.8059\n",
      "Epoch 24/100\n",
      "13255/13255 [==============================] - 1s 61us/step - loss: 0.3042 - acc: 0.8628 - val_loss: 0.3651 - val_acc: 0.8126\n",
      "Epoch 25/100\n",
      "13255/13255 [==============================] - 1s 70us/step - loss: 0.3018 - acc: 0.8671 - val_loss: 0.3492 - val_acc: 0.8202\n",
      "Epoch 26/100\n",
      "13255/13255 [==============================] - 1s 69us/step - loss: 0.2930 - acc: 0.8698 - val_loss: 0.3512 - val_acc: 0.8173\n",
      "Epoch 27/100\n",
      "13255/13255 [==============================] - 1s 82us/step - loss: 0.2933 - acc: 0.8724 - val_loss: 0.3571 - val_acc: 0.8254\n",
      "Epoch 28/100\n",
      "13255/13255 [==============================] - 1s 104us/step - loss: 0.2931 - acc: 0.8692 - val_loss: 0.3400 - val_acc: 0.8311\n",
      "Epoch 29/100\n",
      "13255/13255 [==============================] - 1s 81us/step - loss: 0.2874 - acc: 0.8715 - val_loss: 0.3635 - val_acc: 0.8221\n",
      "Epoch 30/100\n",
      "13255/13255 [==============================] - 1s 60us/step - loss: 0.2861 - acc: 0.8753 - val_loss: 0.3622 - val_acc: 0.8130\n",
      "Epoch 31/100\n",
      "13255/13255 [==============================] - 1s 64us/step - loss: 0.2855 - acc: 0.8745 - val_loss: 0.3606 - val_acc: 0.8268\n",
      "Epoch 32/100\n",
      "13255/13255 [==============================] - 1s 59us/step - loss: 0.2808 - acc: 0.8767 - val_loss: 0.3622 - val_acc: 0.8273\n",
      "Epoch 33/100\n",
      "13255/13255 [==============================] - 1s 65us/step - loss: 0.2784 - acc: 0.8776 - val_loss: 0.3655 - val_acc: 0.8273\n",
      "Epoch 34/100\n",
      "13255/13255 [==============================] - 1s 58us/step - loss: 0.2764 - acc: 0.8825 - val_loss: 0.3694 - val_acc: 0.8330\n",
      "Epoch 35/100\n",
      "13255/13255 [==============================] - 1s 57us/step - loss: 0.2669 - acc: 0.8857 - val_loss: 0.3663 - val_acc: 0.8321\n",
      "Epoch 36/100\n",
      "13255/13255 [==============================] - 1s 63us/step - loss: 0.2694 - acc: 0.8822 - val_loss: 0.3702 - val_acc: 0.8316\n",
      "Epoch 37/100\n",
      "13255/13255 [==============================] - 1s 56us/step - loss: 0.2686 - acc: 0.8834 - val_loss: 0.3506 - val_acc: 0.8397\n",
      "Epoch 38/100\n",
      "13255/13255 [==============================] - 1s 58us/step - loss: 0.2623 - acc: 0.8863 - val_loss: 0.3635 - val_acc: 0.8335\n",
      "Epoch 39/100\n",
      "13255/13255 [==============================] - 1s 79us/step - loss: 0.2699 - acc: 0.8831 - val_loss: 0.3727 - val_acc: 0.8316\n",
      "Epoch 40/100\n",
      "13255/13255 [==============================] - 1s 72us/step - loss: 0.2626 - acc: 0.8876 - val_loss: 0.3665 - val_acc: 0.8454\n",
      "Epoch 41/100\n",
      "13255/13255 [==============================] - 1s 68us/step - loss: 0.2632 - acc: 0.8858 - val_loss: 0.3575 - val_acc: 0.8416\n",
      "Epoch 42/100\n",
      "13255/13255 [==============================] - 1s 68us/step - loss: 0.2606 - acc: 0.8870 - val_loss: 0.3829 - val_acc: 0.8354\n",
      "Epoch 43/100\n",
      "13255/13255 [==============================] - 1s 67us/step - loss: 0.2588 - acc: 0.8886 - val_loss: 0.3696 - val_acc: 0.8425\n",
      "Epoch 44/100\n",
      "13255/13255 [==============================] - 1s 66us/step - loss: 0.2559 - acc: 0.8889 - val_loss: 0.3801 - val_acc: 0.8416\n",
      "Epoch 45/100\n",
      "13255/13255 [==============================] - 1s 84us/step - loss: 0.2613 - acc: 0.8888 - val_loss: 0.3867 - val_acc: 0.8268\n",
      "Epoch 46/100\n",
      "13255/13255 [==============================] - 1s 94us/step - loss: 0.2529 - acc: 0.8900 - val_loss: 0.3866 - val_acc: 0.8368\n",
      "Epoch 47/100\n",
      "13255/13255 [==============================] - 1s 83us/step - loss: 0.2527 - acc: 0.8916 - val_loss: 0.3687 - val_acc: 0.8382\n",
      "Epoch 48/100\n",
      "13255/13255 [==============================] - 1s 67us/step - loss: 0.2530 - acc: 0.8920 - val_loss: 0.3868 - val_acc: 0.8454\n",
      "Epoch 49/100\n",
      "13255/13255 [==============================] - 1s 59us/step - loss: 0.2491 - acc: 0.8927 - val_loss: 0.3892 - val_acc: 0.8421\n",
      "Epoch 50/100\n",
      "13255/13255 [==============================] - 1s 73us/step - loss: 0.2478 - acc: 0.8951 - val_loss: 0.3951 - val_acc: 0.8425\n",
      "Epoch 51/100\n",
      "13255/13255 [==============================] - 1s 70us/step - loss: 0.2506 - acc: 0.8937 - val_loss: 0.3797 - val_acc: 0.8387\n",
      "Epoch 52/100\n",
      "13255/13255 [==============================] - 1s 71us/step - loss: 0.2478 - acc: 0.8915 - val_loss: 0.3953 - val_acc: 0.8421\n",
      "Epoch 53/100\n",
      "13255/13255 [==============================] - 1s 89us/step - loss: 0.2543 - acc: 0.8923 - val_loss: 0.3791 - val_acc: 0.8454\n",
      "Epoch 54/100\n",
      "13255/13255 [==============================] - 1s 60us/step - loss: 0.2431 - acc: 0.8978 - val_loss: 0.3706 - val_acc: 0.8492\n",
      "Epoch 55/100\n",
      "13255/13255 [==============================] - 1s 63us/step - loss: 0.2474 - acc: 0.8964 - val_loss: 0.3957 - val_acc: 0.8421\n",
      "Epoch 56/100\n",
      "13255/13255 [==============================] - 1s 81us/step - loss: 0.2462 - acc: 0.8948 - val_loss: 0.3969 - val_acc: 0.8316\n",
      "Epoch 57/100\n",
      "13255/13255 [==============================] - 1s 91us/step - loss: 0.2416 - acc: 0.8985 - val_loss: 0.3861 - val_acc: 0.8592\n",
      "Epoch 58/100\n",
      "13255/13255 [==============================] - 1s 70us/step - loss: 0.2355 - acc: 0.8985 - val_loss: 0.3981 - val_acc: 0.8435\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13255/13255 [==============================] - 1s 75us/step - loss: 0.2349 - acc: 0.9017 - val_loss: 0.3962 - val_acc: 0.8411\n",
      "Epoch 60/100\n",
      "13255/13255 [==============================] - 1s 85us/step - loss: 0.2415 - acc: 0.8975 - val_loss: 0.3899 - val_acc: 0.8468\n",
      "Epoch 61/100\n",
      "13255/13255 [==============================] - 1s 62us/step - loss: 0.2370 - acc: 0.8993 - val_loss: 0.3983 - val_acc: 0.8473\n",
      "Epoch 62/100\n",
      "13255/13255 [==============================] - 1s 71us/step - loss: 0.2411 - acc: 0.8971 - val_loss: 0.3827 - val_acc: 0.8506\n",
      "Epoch 63/100\n",
      "13255/13255 [==============================] - 1s 67us/step - loss: 0.2384 - acc: 0.8993 - val_loss: 0.3804 - val_acc: 0.8492\n",
      "Epoch 64/100\n",
      "13255/13255 [==============================] - 1s 58us/step - loss: 0.2362 - acc: 0.8994 - val_loss: 0.4000 - val_acc: 0.8468\n",
      "Epoch 65/100\n",
      "13255/13255 [==============================] - 1s 58us/step - loss: 0.2366 - acc: 0.9012 - val_loss: 0.3817 - val_acc: 0.8520\n",
      "Epoch 66/100\n",
      "13255/13255 [==============================] - 1s 58us/step - loss: 0.2388 - acc: 0.8994 - val_loss: 0.4029 - val_acc: 0.8440\n",
      "Epoch 67/100\n",
      "13255/13255 [==============================] - 1s 61us/step - loss: 0.2296 - acc: 0.9018 - val_loss: 0.4018 - val_acc: 0.8468\n",
      "Epoch 68/100\n",
      "13255/13255 [==============================] - 1s 68us/step - loss: 0.2366 - acc: 0.8989 - val_loss: 0.3974 - val_acc: 0.8478\n",
      "Epoch 69/100\n",
      "13255/13255 [==============================] - 1s 82us/step - loss: 0.2302 - acc: 0.9045 - val_loss: 0.4095 - val_acc: 0.8535\n",
      "Epoch 70/100\n",
      "13255/13255 [==============================] - 1s 67us/step - loss: 0.2314 - acc: 0.9019 - val_loss: 0.3932 - val_acc: 0.8559\n",
      "Epoch 71/100\n",
      "13255/13255 [==============================] - 1s 58us/step - loss: 0.2291 - acc: 0.9001 - val_loss: 0.3978 - val_acc: 0.8568\n",
      "Epoch 72/100\n",
      "13255/13255 [==============================] - 1s 101us/step - loss: 0.2248 - acc: 0.9052 - val_loss: 0.4176 - val_acc: 0.8559\n",
      "Epoch 73/100\n",
      "13255/13255 [==============================] - 1s 79us/step - loss: 0.2320 - acc: 0.9031 - val_loss: 0.4114 - val_acc: 0.8492\n",
      "Epoch 74/100\n",
      "13255/13255 [==============================] - 1s 79us/step - loss: 0.2279 - acc: 0.9038 - val_loss: 0.3963 - val_acc: 0.8554\n",
      "Epoch 75/100\n",
      "13255/13255 [==============================] - 1s 92us/step - loss: 0.2255 - acc: 0.9049 - val_loss: 0.4082 - val_acc: 0.8568\n",
      "Epoch 76/100\n",
      "13255/13255 [==============================] - 1s 90us/step - loss: 0.2262 - acc: 0.9074 - val_loss: 0.4084 - val_acc: 0.8611\n",
      "Epoch 77/100\n",
      "13255/13255 [==============================] - 1s 87us/step - loss: 0.2274 - acc: 0.9041 - val_loss: 0.3935 - val_acc: 0.8578\n",
      "Epoch 78/100\n",
      "13255/13255 [==============================] - 1s 87us/step - loss: 0.2245 - acc: 0.9058 - val_loss: 0.4132 - val_acc: 0.8482\n",
      "Epoch 79/100\n",
      "13255/13255 [==============================] - 1s 63us/step - loss: 0.2260 - acc: 0.9061 - val_loss: 0.3974 - val_acc: 0.8568\n",
      "Epoch 80/100\n",
      "13255/13255 [==============================] - 1s 93us/step - loss: 0.2206 - acc: 0.9075 - val_loss: 0.4124 - val_acc: 0.8506\n",
      "Epoch 81/100\n",
      "13255/13255 [==============================] - 1s 72us/step - loss: 0.2254 - acc: 0.9051 - val_loss: 0.4037 - val_acc: 0.8492\n",
      "Epoch 82/100\n",
      "13255/13255 [==============================] - 1s 83us/step - loss: 0.2228 - acc: 0.9077 - val_loss: 0.4015 - val_acc: 0.8573\n",
      "Epoch 83/100\n",
      "13255/13255 [==============================] - 1s 88us/step - loss: 0.2255 - acc: 0.9046 - val_loss: 0.3935 - val_acc: 0.8544\n",
      "Epoch 84/100\n",
      "13255/13255 [==============================] - 1s 61us/step - loss: 0.2274 - acc: 0.9053 - val_loss: 0.3928 - val_acc: 0.8559\n",
      "Epoch 85/100\n",
      "13255/13255 [==============================] - 1s 56us/step - loss: 0.2192 - acc: 0.9093 - val_loss: 0.4068 - val_acc: 0.8530\n",
      "Epoch 86/100\n",
      "13255/13255 [==============================] - 1s 54us/step - loss: 0.2201 - acc: 0.9075 - val_loss: 0.4011 - val_acc: 0.8539\n",
      "Epoch 87/100\n",
      "13255/13255 [==============================] - 1s 55us/step - loss: 0.2251 - acc: 0.9068 - val_loss: 0.3998 - val_acc: 0.8573\n",
      "Epoch 88/100\n",
      "13255/13255 [==============================] - 1s 53us/step - loss: 0.2249 - acc: 0.9042 - val_loss: 0.4094 - val_acc: 0.8559\n",
      "Epoch 89/100\n",
      "13255/13255 [==============================] - 1s 55us/step - loss: 0.2172 - acc: 0.9086 - val_loss: 0.4084 - val_acc: 0.8506\n",
      "Epoch 90/100\n",
      "13255/13255 [==============================] - 1s 56us/step - loss: 0.2203 - acc: 0.9075 - val_loss: 0.4056 - val_acc: 0.8525\n",
      "Epoch 91/100\n",
      "13255/13255 [==============================] - 1s 54us/step - loss: 0.2170 - acc: 0.9092 - val_loss: 0.4160 - val_acc: 0.8587\n",
      "Epoch 92/100\n",
      "13255/13255 [==============================] - 1s 54us/step - loss: 0.2183 - acc: 0.9080 - val_loss: 0.3954 - val_acc: 0.8549\n",
      "Epoch 93/100\n",
      "13255/13255 [==============================] - 1s 55us/step - loss: 0.2133 - acc: 0.9094 - val_loss: 0.4204 - val_acc: 0.8549\n",
      "Epoch 94/100\n",
      "13255/13255 [==============================] - 1s 55us/step - loss: 0.2202 - acc: 0.9077 - val_loss: 0.3973 - val_acc: 0.8582\n",
      "Epoch 95/100\n",
      "13255/13255 [==============================] - 1s 57us/step - loss: 0.2163 - acc: 0.9090 - val_loss: 0.4125 - val_acc: 0.8525\n",
      "Epoch 96/100\n",
      "13255/13255 [==============================] - 1s 54us/step - loss: 0.2119 - acc: 0.9100 - val_loss: 0.4297 - val_acc: 0.8644\n",
      "Epoch 97/100\n",
      "13255/13255 [==============================] - 1s 55us/step - loss: 0.2197 - acc: 0.9089 - val_loss: 0.4230 - val_acc: 0.8625\n",
      "Epoch 98/100\n",
      "13255/13255 [==============================] - 1s 54us/step - loss: 0.2132 - acc: 0.9107 - val_loss: 0.4213 - val_acc: 0.8620\n",
      "Epoch 99/100\n",
      "13255/13255 [==============================] - 1s 55us/step - loss: 0.2169 - acc: 0.9114 - val_loss: 0.4267 - val_acc: 0.8611\n",
      "Epoch 100/100\n",
      "13255/13255 [==============================] - 1s 55us/step - loss: 0.2105 - acc: 0.9135 - val_loss: 0.4287 - val_acc: 0.8554\n",
      "CPU times: user 2min 13s, sys: 21.3 s, total: 2min 34s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = model.fit(X_traino, y_traino,\n",
    "                 validation_data=(X_testo, y_testo),\n",
    "                 epochs=100,\n",
    "#                  batch_size=64,\n",
    "                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129d6af60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1283c8438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8553758326538623"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss += hist.history['loss']\n",
    "test_loss += hist.history['val_loss']\n",
    "train_acc += hist.history['acc']\n",
    "test_acc += hist.history['val_acc']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best') ## I love this loc = 'best' command.\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "test_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7971613727637824"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_testo, model.predict(X_testo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.00100402, 0.00100402, 0.00150602,\n",
       "        0.00150602, 0.00150602, 0.00200803, 0.00200803, 0.00301205,\n",
       "        0.00301205, 0.00351406, 0.00351406, 0.00401606, 0.00401606,\n",
       "        0.00502008, 0.00502008, 0.00502008, 0.00502008, 0.00702811,\n",
       "        0.00702811, 0.00753012, 0.00753012, 0.00853414, 0.00903614,\n",
       "        0.00903614, 0.01154618, 0.01154618, 0.01204819, 0.01204819,\n",
       "        0.01305221, 0.01355422, 0.01455823, 0.01455823, 0.01556225,\n",
       "        0.01556225, 0.01606426, 0.01606426, 0.01656627, 0.01656627,\n",
       "        0.01706827, 0.01757028, 0.01757028, 0.02158635, 0.02158635,\n",
       "        0.02409639, 0.02409639, 0.02459839, 0.02459839, 0.02560241,\n",
       "        0.02560241, 0.02610442, 0.02610442, 0.02811245, 0.02911647,\n",
       "        0.02961847, 0.03062249, 0.03162651, 0.03263052, 0.03413655,\n",
       "        0.03614458, 0.03714859, 0.0376506 , 0.03815261, 0.04016064,\n",
       "        0.04016064, 0.04066265, 0.04066265, 0.04166667, 0.04166667,\n",
       "        0.04317269, 0.04317269, 0.0436747 , 0.0436747 , 0.04417671,\n",
       "        0.04467871, 0.04568273, 0.04618474, 0.04668675, 0.04718876,\n",
       "        0.04718876, 0.04769076, 0.04769076, 0.0502008 , 0.05120482,\n",
       "        0.05170683, 0.05220884, 0.05321285, 0.05522088, 0.05522088,\n",
       "        0.05572289, 0.05722892, 0.062751  , 0.06375502, 0.06927711,\n",
       "        0.07931727, 0.08032129, 0.08082329, 0.08082329, 0.08333333,\n",
       "        0.08634538, 0.08684739, 0.08785141, 0.08935743, 0.08985944,\n",
       "        0.09036145, 0.09287149, 0.0938755 , 0.09688755, 0.09738956,\n",
       "        0.10190763, 0.10491968, 0.10592369, 0.11194779, 0.11495984,\n",
       "        0.11696787, 0.12048193, 0.12148594, 0.13654618, 0.1375502 ,\n",
       "        0.14006024, 0.14106426, 0.14508032, 0.14608434, 0.14859438,\n",
       "        0.14959839, 0.15763052, 0.15913655, 0.16114458, 0.1626506 ,\n",
       "        0.16616466, 0.16716867, 0.18373494, 0.18473896, 0.19427711,\n",
       "        0.19628514, 0.20080321, 0.20180723, 0.20933735, 0.21034137,\n",
       "        0.21184739, 0.21285141, 0.21335341, 0.21435743, 0.23343373,\n",
       "        0.23493976, 0.23895582, 0.24196787, 0.24246988, 0.2434739 ,\n",
       "        0.2685743 , 0.26957831, 0.2876506 , 0.29016064, 0.29467871,\n",
       "        0.29568273, 0.29668675, 0.29819277, 0.2996988 , 0.30070281,\n",
       "        0.3062249 , 0.30722892, 0.31024096, 0.31124498, 0.31726908,\n",
       "        0.31827309, 0.3187751 , 0.31977912, 0.32128514, 0.32228916,\n",
       "        0.33032129, 0.3313253 , 0.34588353, 0.34688755, 0.36094378,\n",
       "        0.36194779, 0.36445783, 0.36646586, 0.36947791, 0.37148594,\n",
       "        0.37600402, 0.37700803, 0.37851406, 0.37951807, 0.38855422,\n",
       "        0.38955823, 0.39658635, 0.39759036, 0.40261044, 0.40361446,\n",
       "        0.40763052, 0.41014056, 0.41214859, 0.41315261, 0.41917671,\n",
       "        0.42018072, 0.42068273, 0.42218876, 0.4246988 , 0.42570281,\n",
       "        0.44226908, 0.44327309, 0.4623494 , 0.46335341, 0.47941767,\n",
       "        0.48092369, 0.48242972, 0.48343373, 0.50552209, 0.5065261 ,\n",
       "        0.50753012, 0.50903614, 0.51907631, 0.52108434, 0.53413655,\n",
       "        0.53514056, 0.54668675, 0.54769076, 0.56526104, 0.56626506,\n",
       "        0.57379518, 0.5747992 , 0.57881526, 0.57981928, 0.58082329,\n",
       "        0.58182731, 0.60090361, 0.60190763, 0.61495984, 0.61596386,\n",
       "        0.64056225, 0.64257028, 0.64608434, 0.64708835, 0.65261044,\n",
       "        0.65361446, 0.65461847, 0.65712851, 0.6746988 , 0.67570281,\n",
       "        0.67620482, 0.67720884, 0.68473896, 0.68574297, 0.69226908,\n",
       "        0.6937751 , 0.70281124, 0.70381526, 0.72339357, 0.72439759,\n",
       "        0.73192771, 0.73393574, 0.77208835, 0.77309237, 0.78062249,\n",
       "        0.78162651, 0.78514056, 0.78614458, 0.83935743, 0.84036145,\n",
       "        0.85943775, 0.86044177, 0.88303213, 0.88403614, 0.89056225,\n",
       "        1.        ]),\n",
       " array([0.00909091, 0.16363636, 0.16363636, 0.18181818, 0.18181818,\n",
       "        0.2       , 0.21818182, 0.21818182, 0.28181818, 0.28181818,\n",
       "        0.3       , 0.3       , 0.31818182, 0.31818182, 0.33636364,\n",
       "        0.33636364, 0.34545455, 0.36363636, 0.40909091, 0.40909091,\n",
       "        0.41818182, 0.41818182, 0.48181818, 0.48181818, 0.49090909,\n",
       "        0.52727273, 0.52727273, 0.53636364, 0.53636364, 0.55454545,\n",
       "        0.55454545, 0.56363636, 0.56363636, 0.57272727, 0.57272727,\n",
       "        0.58181818, 0.58181818, 0.59090909, 0.59090909, 0.6       ,\n",
       "        0.6       , 0.60909091, 0.61818182, 0.61818182, 0.62727273,\n",
       "        0.62727273, 0.64545455, 0.64545455, 0.65454545, 0.65454545,\n",
       "        0.66363636, 0.66363636, 0.67272727, 0.68181818, 0.68181818,\n",
       "        0.69090909, 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "        0.7       , 0.73636364, 0.73636364, 0.74545455, 0.74545455,\n",
       "        0.75454545, 0.75454545, 0.76363636, 0.76363636, 0.77272727,\n",
       "        0.77272727, 0.79090909, 0.79090909, 0.8       , 0.80909091,\n",
       "        0.82727273, 0.83636364, 0.83636364, 0.84545455, 0.84545455,\n",
       "        0.85454545, 0.85454545, 0.86363636, 0.86363636, 0.87272727,\n",
       "        0.87272727, 0.88181818, 0.88181818, 0.88181818, 0.89090909,\n",
       "        0.89090909, 0.89090909, 0.9       , 0.90909091, 0.94545455,\n",
       "        0.94545455, 0.94545455, 0.94545455, 0.95454545, 0.95454545,\n",
       "        0.97272727, 0.97272727, 0.97272727, 0.97272727, 0.98181818,\n",
       "        0.98181818, 0.98181818, 0.98181818, 0.98181818, 0.98181818,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " array([9.99252021e-01, 9.91663218e-01, 9.90881562e-01, 9.89867449e-01,\n",
       "        9.89588976e-01, 9.89441872e-01, 9.87989306e-01, 9.85715330e-01,\n",
       "        9.80831087e-01, 9.79797423e-01, 9.79547203e-01, 9.79173958e-01,\n",
       "        9.77568150e-01, 9.77113664e-01, 9.75313842e-01, 9.74832058e-01,\n",
       "        9.74377155e-01, 9.74255204e-01, 9.70976174e-01, 9.67610121e-01,\n",
       "        9.66872513e-01, 9.64791775e-01, 9.56658661e-01, 9.47632313e-01,\n",
       "        9.44910586e-01, 9.39747036e-01, 9.32639360e-01, 9.30686533e-01,\n",
       "        9.30569768e-01, 9.28874910e-01, 9.26423669e-01, 9.25442338e-01,\n",
       "        9.24032450e-01, 9.23404992e-01, 9.20313895e-01, 9.19551611e-01,\n",
       "        9.19409156e-01, 9.18599546e-01, 9.17205572e-01, 9.17116404e-01,\n",
       "        9.13475692e-01, 9.13097918e-01, 9.12308753e-01, 9.03308213e-01,\n",
       "        9.02249694e-01, 8.88670206e-01, 8.87511492e-01, 8.83667409e-01,\n",
       "        8.77214372e-01, 8.75775158e-01, 8.72716784e-01, 8.72063458e-01,\n",
       "        8.71180892e-01, 8.70099187e-01, 8.60657990e-01, 8.57120574e-01,\n",
       "        8.54848862e-01, 8.54565144e-01, 8.50429356e-01, 8.48927915e-01,\n",
       "        8.47752094e-01, 8.46835971e-01, 8.45802665e-01, 8.44546258e-01,\n",
       "        8.36003900e-01, 8.33657265e-01, 8.31920862e-01, 8.30662966e-01,\n",
       "        8.24714065e-01, 8.17935884e-01, 8.13307643e-01, 8.05184603e-01,\n",
       "        7.94868350e-01, 7.94192076e-01, 7.91696429e-01, 7.87588775e-01,\n",
       "        7.87475526e-01, 7.84994602e-01, 7.82577634e-01, 7.81853020e-01,\n",
       "        7.81161785e-01, 7.80677319e-01, 7.79240549e-01, 7.56542921e-01,\n",
       "        7.51491725e-01, 7.51051426e-01, 7.47189283e-01, 7.47114182e-01,\n",
       "        7.30881274e-01, 7.29874969e-01, 7.28749275e-01, 7.28395641e-01,\n",
       "        7.28356183e-01, 7.25951552e-01, 7.20371306e-01, 6.15641534e-01,\n",
       "        6.09577060e-01, 6.06252491e-01, 6.05491519e-01, 5.47944486e-01,\n",
       "        5.45948148e-01, 5.44369400e-01, 5.42457283e-01, 5.27365029e-01,\n",
       "        5.26934803e-01, 5.23620903e-01, 5.20906448e-01, 5.04270315e-01,\n",
       "        4.96708274e-01, 4.94391352e-01, 4.92670804e-01, 4.92181420e-01,\n",
       "        4.88056391e-01, 4.71279651e-01, 4.34016913e-01, 4.31759119e-01,\n",
       "        3.98769855e-01, 3.80557150e-01, 1.96373224e-01, 1.89857498e-01,\n",
       "        1.81769252e-01, 1.78574562e-01, 1.53443485e-01, 1.53442770e-01,\n",
       "        1.45258233e-01, 1.42858461e-01, 1.14029467e-01, 1.10296957e-01,\n",
       "        1.03265934e-01, 1.02933906e-01, 8.96598473e-02, 8.91142190e-02,\n",
       "        4.75742556e-02, 4.56147268e-02, 3.09550408e-02, 3.08086760e-02,\n",
       "        2.68500131e-02, 2.66787931e-02, 2.05609873e-02, 2.04389095e-02,\n",
       "        1.97795574e-02, 1.95747148e-02, 1.85229015e-02, 1.83804240e-02,\n",
       "        1.03590600e-02, 1.03557762e-02, 9.25962813e-03, 8.82751122e-03,\n",
       "        8.80891085e-03, 8.69809464e-03, 4.70347889e-03, 4.67060367e-03,\n",
       "        2.56111682e-03, 2.52853869e-03, 2.25574384e-03, 2.25425465e-03,\n",
       "        2.23372248e-03, 2.23119883e-03, 2.07342394e-03, 2.02921918e-03,\n",
       "        1.68000744e-03, 1.67597912e-03, 1.40129216e-03, 1.38485187e-03,\n",
       "        1.05365249e-03, 1.05019275e-03, 1.01697911e-03, 9.96025861e-04,\n",
       "        9.24297958e-04, 9.21708881e-04, 6.68445544e-04, 6.65972591e-04,\n",
       "        4.82497067e-04, 4.78166650e-04, 3.17281549e-04, 3.09749972e-04,\n",
       "        2.81829794e-04, 2.76196894e-04, 2.36081774e-04, 2.30792604e-04,\n",
       "        1.74025336e-04, 1.71705746e-04, 1.67454797e-04, 1.61228178e-04,\n",
       "        8.71516677e-05, 8.55255712e-05, 5.28966593e-05, 5.21255570e-05,\n",
       "        3.99318706e-05, 3.95222596e-05, 3.04051719e-05, 3.01201235e-05,\n",
       "        2.67824053e-05, 2.58668897e-05, 1.62617744e-05, 1.37116067e-05,\n",
       "        1.36688350e-05, 1.36002336e-05, 1.24452636e-05, 1.23201726e-05,\n",
       "        5.14304929e-06, 4.93409880e-06, 1.84611031e-06, 1.82291024e-06,\n",
       "        8.56688189e-07, 8.19789534e-07, 8.11254722e-07, 7.81102187e-07,\n",
       "        2.36145908e-07, 2.23672288e-07, 2.19910333e-07, 2.10125478e-07,\n",
       "        8.72961294e-08, 8.21740258e-08, 2.96127691e-08, 2.93417752e-08,\n",
       "        1.20002488e-08, 1.16972485e-08, 2.30606334e-09, 2.27481056e-09,\n",
       "        1.13546905e-09, 1.09075626e-09, 7.70543629e-10, 7.62146291e-10,\n",
       "        7.05561443e-10, 7.03235803e-10, 9.95591040e-11, 9.67185845e-11,\n",
       "        2.32562442e-11, 2.24923656e-11, 1.05894536e-12, 9.58822106e-13,\n",
       "        6.99733240e-13, 6.87252284e-13, 3.97712408e-13, 3.53186691e-13,\n",
       "        3.32009729e-13, 3.27512675e-13, 2.43680198e-14, 2.24811794e-14,\n",
       "        2.15380336e-14, 2.12744454e-14, 1.17384706e-14, 1.16348649e-14,\n",
       "        5.37594490e-15, 5.14398874e-15, 1.42302255e-15, 1.22311949e-15,\n",
       "        6.88028650e-17, 6.63569052e-17, 1.68536015e-17, 1.55514587e-17,\n",
       "        2.83110017e-21, 2.64213928e-21, 3.52403150e-22, 3.39135595e-22,\n",
       "        1.72303415e-22, 1.64630197e-22, 3.90514044e-29, 3.36341216e-29,\n",
       "        5.78311717e-32, 5.17474595e-32, 2.85942709e-37, 1.49850060e-37,\n",
       "        1.22835609e-38, 0.00000000e+00], dtype=float32))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_curve(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.0\n",
      "Confusion Matrix\n",
      "[[ 201 1791]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.10      0.18      1992\n",
      "        Yes       0.06      1.00      0.11       110\n",
      "\n",
      "avg / total       0.95      0.15      0.18      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.01\n",
      "Confusion Matrix\n",
      "[[1503  489]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.75      0.86      1992\n",
      "        Yes       0.18      1.00      0.31       110\n",
      "\n",
      "avg / total       0.96      0.77      0.83      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.02\n",
      "Confusion Matrix\n",
      "[[1561  431]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.78      0.88      1992\n",
      "        Yes       0.20      1.00      0.34       110\n",
      "\n",
      "avg / total       0.96      0.79      0.85      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.03\n",
      "Confusion Matrix\n",
      "[[1589  403]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.80      0.89      1992\n",
      "        Yes       0.21      1.00      0.35       110\n",
      "\n",
      "avg / total       0.96      0.81      0.86      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.04\n",
      "Confusion Matrix\n",
      "[[1609  383]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.81      0.89      1992\n",
      "        Yes       0.22      1.00      0.36       110\n",
      "\n",
      "avg / total       0.96      0.82      0.87      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.05\n",
      "Confusion Matrix\n",
      "[[1627  365]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.82      0.90      1992\n",
      "        Yes       0.23      1.00      0.38       110\n",
      "\n",
      "avg / total       0.96      0.83      0.87      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.06\n",
      "Confusion Matrix\n",
      "[[1639  353]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.82      0.90      1992\n",
      "        Yes       0.24      1.00      0.38       110\n",
      "\n",
      "avg / total       0.96      0.83      0.88      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.07\n",
      "Confusion Matrix\n",
      "[[1650  342]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.83      0.91      1992\n",
      "        Yes       0.24      1.00      0.39       110\n",
      "\n",
      "avg / total       0.96      0.84      0.88      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.08\n",
      "Confusion Matrix\n",
      "[[1659  333]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.83      0.91      1992\n",
      "        Yes       0.25      1.00      0.40       110\n",
      "\n",
      "avg / total       0.96      0.84      0.88      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.09\n",
      "Confusion Matrix\n",
      "[[1666  326]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.84      0.91      1992\n",
      "        Yes       0.25      1.00      0.40       110\n",
      "\n",
      "avg / total       0.96      0.84      0.88      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.1\n",
      "Confusion Matrix\n",
      "[[1672  320]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.84      0.91      1992\n",
      "        Yes       0.26      1.00      0.41       110\n",
      "\n",
      "avg / total       0.96      0.85      0.89      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.11\n",
      "Confusion Matrix\n",
      "[[1677  315]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.84      0.91      1992\n",
      "        Yes       0.26      1.00      0.41       110\n",
      "\n",
      "avg / total       0.96      0.85      0.89      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.12\n",
      "Confusion Matrix\n",
      "[[1680  312]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.84      0.92      1992\n",
      "        Yes       0.26      1.00      0.41       110\n",
      "\n",
      "avg / total       0.96      0.85      0.89      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.13\n",
      "Confusion Matrix\n",
      "[[1682  310]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.84      0.92      1992\n",
      "        Yes       0.26      1.00      0.42       110\n",
      "\n",
      "avg / total       0.96      0.85      0.89      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.14\n",
      "Confusion Matrix\n",
      "[[1691  301]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.85      0.92      1992\n",
      "        Yes       0.27      1.00      0.42       110\n",
      "\n",
      "avg / total       0.96      0.86      0.89      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.15\n",
      "Confusion Matrix\n",
      "[[1693  299]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.85      0.92      1992\n",
      "        Yes       0.27      1.00      0.42       110\n",
      "\n",
      "avg / total       0.96      0.86      0.89      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.16\n",
      "Confusion Matrix\n",
      "[[1699  293]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.85      0.92      1992\n",
      "        Yes       0.27      1.00      0.43       110\n",
      "\n",
      "avg / total       0.96      0.86      0.89      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.17\n",
      "Confusion Matrix\n",
      "[[1700  292]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.85      0.92      1992\n",
      "        Yes       0.27      1.00      0.43       110\n",
      "\n",
      "avg / total       0.96      0.86      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.18\n",
      "Confusion Matrix\n",
      "[[1703  289]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.85      0.92      1992\n",
      "        Yes       0.28      1.00      0.43       110\n",
      "\n",
      "avg / total       0.96      0.86      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.19\n",
      "Confusion Matrix\n",
      "[[1705  287]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.86      0.92      1992\n",
      "        Yes       0.28      1.00      0.43       110\n",
      "\n",
      "avg / total       0.96      0.86      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.2\n",
      "Confusion Matrix\n",
      "[[1705  287]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.86      0.92      1992\n",
      "        Yes       0.28      1.00      0.43       110\n",
      "\n",
      "avg / total       0.96      0.86      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.21\n",
      "Confusion Matrix\n",
      "[[1705  287]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.86      0.92      1992\n",
      "        Yes       0.28      1.00      0.43       110\n",
      "\n",
      "avg / total       0.96      0.86      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.22\n",
      "Confusion Matrix\n",
      "[[1709  283]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.86      0.92      1992\n",
      "        Yes       0.28      1.00      0.44       110\n",
      "\n",
      "avg / total       0.96      0.87      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.23\n",
      "Confusion Matrix\n",
      "[[1709  283]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.86      0.92      1992\n",
      "        Yes       0.28      1.00      0.44       110\n",
      "\n",
      "avg / total       0.96      0.87      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.24\n",
      "Confusion Matrix\n",
      "[[1713  279]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.86      0.92      1992\n",
      "        Yes       0.28      1.00      0.44       110\n",
      "\n",
      "avg / total       0.96      0.87      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.25\n",
      "Confusion Matrix\n",
      "[[1713  279]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.86      0.92      1992\n",
      "        Yes       0.28      1.00      0.44       110\n",
      "\n",
      "avg / total       0.96      0.87      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.26\n",
      "Confusion Matrix\n",
      "[[1716  276]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.86      0.93      1992\n",
      "        Yes       0.28      1.00      0.44       110\n",
      "\n",
      "avg / total       0.96      0.87      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.27\n",
      "Confusion Matrix\n",
      "[[1724  268]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.87      0.93      1992\n",
      "        Yes       0.29      1.00      0.45       110\n",
      "\n",
      "avg / total       0.96      0.87      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.28\n",
      "Confusion Matrix\n",
      "[[1727  265]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.87      0.93      1992\n",
      "        Yes       0.29      1.00      0.45       110\n",
      "\n",
      "avg / total       0.96      0.87      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.29\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1730  262]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.87      0.93      1992\n",
      "        Yes       0.30      1.00      0.46       110\n",
      "\n",
      "avg / total       0.96      0.88      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.3\n",
      "Confusion Matrix\n",
      "[[1730  262]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.87      0.93      1992\n",
      "        Yes       0.30      1.00      0.46       110\n",
      "\n",
      "avg / total       0.96      0.88      0.90      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.31\n",
      "Confusion Matrix\n",
      "[[1734  258]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.87      0.93      1992\n",
      "        Yes       0.30      1.00      0.46       110\n",
      "\n",
      "avg / total       0.96      0.88      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.32\n",
      "Confusion Matrix\n",
      "[[1736  256]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.87      0.93      1992\n",
      "        Yes       0.30      1.00      0.46       110\n",
      "\n",
      "avg / total       0.96      0.88      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.33\n",
      "Confusion Matrix\n",
      "[[1740  252]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.87      0.93      1992\n",
      "        Yes       0.30      1.00      0.47       110\n",
      "\n",
      "avg / total       0.96      0.88      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.34\n",
      "Confusion Matrix\n",
      "[[1744  248]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.93      1992\n",
      "        Yes       0.31      1.00      0.47       110\n",
      "\n",
      "avg / total       0.96      0.88      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.35000000000000003\n",
      "Confusion Matrix\n",
      "[[1746  246]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.93      1992\n",
      "        Yes       0.31      1.00      0.47       110\n",
      "\n",
      "avg / total       0.96      0.88      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.36\n",
      "Confusion Matrix\n",
      "[[1748  244]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.93      1992\n",
      "        Yes       0.31      1.00      0.47       110\n",
      "\n",
      "avg / total       0.96      0.88      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.37\n",
      "Confusion Matrix\n",
      "[[1748  244]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.93      1992\n",
      "        Yes       0.31      1.00      0.47       110\n",
      "\n",
      "avg / total       0.96      0.88      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.38\n",
      "Confusion Matrix\n",
      "[[1749  243]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.94      1992\n",
      "        Yes       0.31      1.00      0.48       110\n",
      "\n",
      "avg / total       0.96      0.88      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.39\n",
      "Confusion Matrix\n",
      "[[1750  242]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.94      1992\n",
      "        Yes       0.31      1.00      0.48       110\n",
      "\n",
      "avg / total       0.96      0.88      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.4\n",
      "Confusion Matrix\n",
      "[[1750  242]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.94      1992\n",
      "        Yes       0.31      1.00      0.48       110\n",
      "\n",
      "avg / total       0.96      0.88      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.41000000000000003\n",
      "Confusion Matrix\n",
      "[[1751  241]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.94      1992\n",
      "        Yes       0.31      1.00      0.48       110\n",
      "\n",
      "avg / total       0.96      0.89      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.42\n",
      "Confusion Matrix\n",
      "[[1753  239]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.94      1992\n",
      "        Yes       0.32      1.00      0.48       110\n",
      "\n",
      "avg / total       0.96      0.89      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.43\n",
      "Confusion Matrix\n",
      "[[1755  237]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.94      1992\n",
      "        Yes       0.32      1.00      0.48       110\n",
      "\n",
      "avg / total       0.96      0.89      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.44\n",
      "Confusion Matrix\n",
      "[[1757  235]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.94      1992\n",
      "        Yes       0.32      1.00      0.48       110\n",
      "\n",
      "avg / total       0.96      0.89      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.45\n",
      "Confusion Matrix\n",
      "[[1758  234]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.94      1992\n",
      "        Yes       0.32      1.00      0.48       110\n",
      "\n",
      "avg / total       0.96      0.89      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.46\n",
      "Confusion Matrix\n",
      "[[1761  231]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.88      0.94      1992\n",
      "        Yes       0.32      1.00      0.49       110\n",
      "\n",
      "avg / total       0.96      0.89      0.91      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.47000000000000003\n",
      "Confusion Matrix\n",
      "[[1766  226]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.89      0.94      1992\n",
      "        Yes       0.33      1.00      0.49       110\n",
      "\n",
      "avg / total       0.96      0.89      0.92      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.48\n",
      "Confusion Matrix\n",
      "[[1775  217]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.89      0.94      1992\n",
      "        Yes       0.34      1.00      0.50       110\n",
      "\n",
      "avg / total       0.97      0.90      0.92      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.49\n",
      "Confusion Matrix\n",
      "[[1778  214]\n",
      " [   0  110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.89      0.94      1992\n",
      "        Yes       0.34      1.00      0.51       110\n",
      "\n",
      "avg / total       0.97      0.90      0.92      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.5\n",
      "Confusion Matrix\n",
      "[[1788  204]\n",
      " [   2  108]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.90      0.95      1992\n",
      "        Yes       0.35      0.98      0.51       110\n",
      "\n",
      "avg / total       0.96      0.90      0.92      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.51\n",
      "Confusion Matrix\n",
      "[[1797  195]\n",
      " [   2  108]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.90      0.95      1992\n",
      "        Yes       0.36      0.98      0.52       110\n",
      "\n",
      "avg / total       0.97      0.91      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.52\n",
      "Confusion Matrix\n",
      "[[1797  195]\n",
      " [   2  108]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.90      0.95      1992\n",
      "        Yes       0.36      0.98      0.52       110\n",
      "\n",
      "avg / total       0.97      0.91      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.53\n",
      "Confusion Matrix\n",
      "[[1799  193]\n",
      " [   2  108]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.90      0.95      1992\n",
      "        Yes       0.36      0.98      0.53       110\n",
      "\n",
      "avg / total       0.97      0.91      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.54\n",
      "Confusion Matrix\n",
      "[[1807  185]\n",
      " [   3  107]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.91      0.95      1992\n",
      "        Yes       0.37      0.97      0.53       110\n",
      "\n",
      "avg / total       0.97      0.91      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.55\n",
      "Confusion Matrix\n",
      "[[1815  177]\n",
      " [   3  107]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.91      0.95      1992\n",
      "        Yes       0.38      0.97      0.54       110\n",
      "\n",
      "avg / total       0.97      0.91      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.56\n",
      "Confusion Matrix\n",
      "[[1821  171]\n",
      " [   5  105]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.91      0.95      1992\n",
      "        Yes       0.38      0.95      0.54       110\n",
      "\n",
      "avg / total       0.96      0.92      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.5700000000000001\n",
      "Confusion Matrix\n",
      "[[1821  171]\n",
      " [   5  105]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.91      0.95      1992\n",
      "        Yes       0.38      0.95      0.54       110\n",
      "\n",
      "avg / total       0.96      0.92      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.58\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1823  169]\n",
      " [   5  105]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.95      1992\n",
      "        Yes       0.38      0.95      0.55       110\n",
      "\n",
      "avg / total       0.97      0.92      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.59\n",
      "Confusion Matrix\n",
      "[[1824  168]\n",
      " [   5  105]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.95      1992\n",
      "        Yes       0.38      0.95      0.55       110\n",
      "\n",
      "avg / total       0.97      0.92      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.6\n",
      "Confusion Matrix\n",
      "[[1826  166]\n",
      " [   5  105]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.96      1992\n",
      "        Yes       0.39      0.95      0.55       110\n",
      "\n",
      "avg / total       0.97      0.92      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.61\n",
      "Confusion Matrix\n",
      "[[1827  165]\n",
      " [   6  104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.96      1992\n",
      "        Yes       0.39      0.95      0.55       110\n",
      "\n",
      "avg / total       0.96      0.92      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.62\n",
      "Confusion Matrix\n",
      "[[1827  165]\n",
      " [   6  104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.96      1992\n",
      "        Yes       0.39      0.95      0.55       110\n",
      "\n",
      "avg / total       0.96      0.92      0.93      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.63\n",
      "Confusion Matrix\n",
      "[[1834  158]\n",
      " [   6  104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.96      1992\n",
      "        Yes       0.40      0.95      0.56       110\n",
      "\n",
      "avg / total       0.97      0.92      0.94      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.64\n",
      "Confusion Matrix\n",
      "[[1834  158]\n",
      " [   6  104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.96      1992\n",
      "        Yes       0.40      0.95      0.56       110\n",
      "\n",
      "avg / total       0.97      0.92      0.94      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.65\n",
      "Confusion Matrix\n",
      "[[1835  157]\n",
      " [   6  104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.96      1992\n",
      "        Yes       0.40      0.95      0.56       110\n",
      "\n",
      "avg / total       0.97      0.92      0.94      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.66\n",
      "Confusion Matrix\n",
      "[[1838  154]\n",
      " [   6  104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.96      1992\n",
      "        Yes       0.40      0.95      0.57       110\n",
      "\n",
      "avg / total       0.97      0.92      0.94      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.67\n",
      "Confusion Matrix\n",
      "[[1838  154]\n",
      " [   6  104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.96      1992\n",
      "        Yes       0.40      0.95      0.57       110\n",
      "\n",
      "avg / total       0.97      0.92      0.94      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.68\n",
      "Confusion Matrix\n",
      "[[1838  154]\n",
      " [   6  104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.96      1992\n",
      "        Yes       0.40      0.95      0.57       110\n",
      "\n",
      "avg / total       0.97      0.92      0.94      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.6900000000000001\n",
      "Confusion Matrix\n",
      "[[1839  153]\n",
      " [   6  104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.92      0.96      1992\n",
      "        Yes       0.40      0.95      0.57       110\n",
      "\n",
      "avg / total       0.97      0.92      0.94      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.7000000000000001\n",
      "Confusion Matrix\n",
      "[[1845  147]\n",
      " [   6  104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.93      0.96      1992\n",
      "        Yes       0.41      0.95      0.58       110\n",
      "\n",
      "avg / total       0.97      0.93      0.94      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.71\n",
      "Confusion Matrix\n",
      "[[1846  146]\n",
      " [   6  104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       1.00      0.93      0.96      1992\n",
      "        Yes       0.42      0.95      0.58       110\n",
      "\n",
      "avg / total       0.97      0.93      0.94      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.72\n",
      "Confusion Matrix\n",
      "[[1854  138]\n",
      " [  10  100]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.99      0.93      0.96      1992\n",
      "        Yes       0.42      0.91      0.57       110\n",
      "\n",
      "avg / total       0.96      0.93      0.94      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.73\n",
      "Confusion Matrix\n",
      "[[1872  120]\n",
      " [  12   98]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.99      0.94      0.97      1992\n",
      "        Yes       0.45      0.89      0.60       110\n",
      "\n",
      "avg / total       0.97      0.94      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.74\n",
      "Confusion Matrix\n",
      "[[1881  111]\n",
      " [  13   97]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.99      0.94      0.97      1992\n",
      "        Yes       0.47      0.88      0.61       110\n",
      "\n",
      "avg / total       0.97      0.94      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.75\n",
      "Confusion Matrix\n",
      "[[1886  106]\n",
      " [  14   96]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.99      0.95      0.97      1992\n",
      "        Yes       0.48      0.87      0.62       110\n",
      "\n",
      "avg / total       0.97      0.94      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.76\n",
      "Confusion Matrix\n",
      "[[1890  102]\n",
      " [  15   95]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.99      0.95      0.97      1992\n",
      "        Yes       0.48      0.86      0.62       110\n",
      "\n",
      "avg / total       0.97      0.94      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.77\n",
      "Confusion Matrix\n",
      "[[1891  101]\n",
      " [  17   93]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.99      0.95      0.97      1992\n",
      "        Yes       0.48      0.85      0.61       110\n",
      "\n",
      "avg / total       0.96      0.94      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.78\n",
      "Confusion Matrix\n",
      "[[1896   96]\n",
      " [  18   92]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.99      0.95      0.97      1992\n",
      "        Yes       0.49      0.84      0.62       110\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.79\n",
      "Confusion Matrix\n",
      "[[1902   90]\n",
      " [  21   89]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.99      0.95      0.97      1992\n",
      "        Yes       0.50      0.81      0.62       110\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.8\n",
      "Confusion Matrix\n",
      "[[1906   86]\n",
      " [  22   88]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.99      0.96      0.97      1992\n",
      "        Yes       0.51      0.80      0.62       110\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.81\n",
      "Confusion Matrix\n",
      "[[1907   85]\n",
      " [  24   86]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.99      0.96      0.97      1992\n",
      "        Yes       0.50      0.78      0.61       110\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.8200000000000001\n",
      "Confusion Matrix\n",
      "[[1910   82]\n",
      " [  31   79]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.96      0.97      1992\n",
      "        Yes       0.49      0.72      0.58       110\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.8300000000000001\n",
      "Confusion Matrix\n",
      "[[1913   79]\n",
      " [  32   78]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.96      0.97      1992\n",
      "        Yes       0.50      0.71      0.58       110\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.84\n",
      "Confusion Matrix\n",
      "[[1916   76]\n",
      " [  33   77]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.96      0.97      1992\n",
      "        Yes       0.50      0.70      0.59       110\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.85\n",
      "Confusion Matrix\n",
      "[[1921   71]\n",
      " [  36   74]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.96      0.97      1992\n",
      "        Yes       0.51      0.67      0.58       110\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.86\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1932   60]\n",
      " [  38   72]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.97      0.98      1992\n",
      "        Yes       0.55      0.65      0.60       110\n",
      "\n",
      "avg / total       0.96      0.95      0.96      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.87\n",
      "Confusion Matrix\n",
      "[[1935   57]\n",
      " [  41   69]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.97      0.98      1992\n",
      "        Yes       0.55      0.63      0.58       110\n",
      "\n",
      "avg / total       0.96      0.95      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.88\n",
      "Confusion Matrix\n",
      "[[1941   51]\n",
      " [  41   69]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.97      0.98      1992\n",
      "        Yes       0.57      0.63      0.60       110\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.89\n",
      "Confusion Matrix\n",
      "[[1941   51]\n",
      " [  42   68]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.97      0.98      1992\n",
      "        Yes       0.57      0.62      0.59       110\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.9\n",
      "Confusion Matrix\n",
      "[[1942   50]\n",
      " [  42   68]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.97      0.98      1992\n",
      "        Yes       0.58      0.62      0.60       110\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.91\n",
      "Confusion Matrix\n",
      "[[1954   38]\n",
      " [  44   66]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.98      0.98      1992\n",
      "        Yes       0.63      0.60      0.62       110\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.92\n",
      "Confusion Matrix\n",
      "[[1959   33]\n",
      " [  46   64]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.98      0.98      1992\n",
      "        Yes       0.66      0.58      0.62       110\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.93\n",
      "Confusion Matrix\n",
      "[[1966   26]\n",
      " [  47   63]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.99      0.98      1992\n",
      "        Yes       0.71      0.57      0.63       110\n",
      "\n",
      "avg / total       0.96      0.97      0.96      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.9400000000000001\n",
      "Confusion Matrix\n",
      "[[1975   17]\n",
      " [  50   60]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.98      0.99      0.98      1992\n",
      "        Yes       0.78      0.55      0.64       110\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.9500000000000001\n",
      "Confusion Matrix\n",
      "[[1981   11]\n",
      " [  57   53]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.97      0.99      0.98      1992\n",
      "        Yes       0.83      0.48      0.61       110\n",
      "\n",
      "avg / total       0.96      0.97      0.96      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.96\n",
      "Confusion Matrix\n",
      "[[1982   10]\n",
      " [  63   47]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.97      0.99      0.98      1992\n",
      "        Yes       0.82      0.43      0.56       110\n",
      "\n",
      "avg / total       0.96      0.97      0.96      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.97\n",
      "Confusion Matrix\n",
      "[[1983    9]\n",
      " [  73   37]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      1.00      0.98      1992\n",
      "        Yes       0.80      0.34      0.47       110\n",
      "\n",
      "avg / total       0.96      0.96      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.98\n",
      "Confusion Matrix\n",
      "[[1988    4]\n",
      " [  79   31]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      1.00      0.98      1992\n",
      "        Yes       0.89      0.28      0.43       110\n",
      "\n",
      "avg / total       0.96      0.96      0.95      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 0.99\n",
      "Confusion Matrix\n",
      "[[1991    1]\n",
      " [  96   14]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      1.00      0.98      1992\n",
      "        Yes       0.93      0.13      0.22       110\n",
      "\n",
      "avg / total       0.95      0.95      0.94      2102\n",
      "\n",
      "*******************************\n",
      "\n",
      "Threshold: 1.0\n",
      "Confusion Matrix\n",
      "[[1992    0]\n",
      " [ 110    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      1.00      0.97      1992\n",
      "        Yes       0.00      0.00      0.00       110\n",
      "\n",
      "avg / total       0.90      0.95      0.92      2102\n",
      "\n",
      "*******************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evankranzler/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.linspace(0, 1, 101):\n",
    "    print('Threshold: {}'.format(threshold))\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test, (model.predict(X_test) > threshold).astype(float)))\n",
    "    print(classification_report(y_test, (model.predict(X_test) > threshold).astype(float), target_names=['No', 'Yes']))\n",
    "    print('*******************************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3992154496077248"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testo.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAGvFJREFUeJzt3Xl4HPWd5/H3V7IuW7ZlW/J939jYDiDMlcPBYMxlh0lCMBBChg2BrDPZJMOGWWaZhOzOTJLNZJKsZ8ABBgIPVzLPZJzBLBBzOIAvOYDxbfm+JVmybMm69d0/uvEIIVttqdXVXf15PY8fuqtK3Z9y2x/Kv676lbk7IiISLhlBBxARkfhTuYuIhJDKXUQkhFTuIiIhpHIXEQkhlbuISAip3EVEQkjlLiISQip3EZEQ6hXUGxcWFvrYsWODensRkZS0fv36Cncv6my7wMp97NixlJSUBPX2IiIpycz2xrKdhmVEREJI5S4iEkIqdxGREFK5i4iEkMpdRCSEOi13M3vczMrMbOMZ1puZ/cLMSs1sg5ldGP+YIiJyLmI5cn8CmH+W9dcCk6K/7gb+ufuxRESkOzo9z93dV5rZ2LNsshD4tUfu17fazArMbJi7H45TRhHppt+/f4gdR08GHUOi5p43hFmjCnr0PeJxEdMIYH+b5weiyz5W7mZ2N5Gje0aPHh2HtxaRzpyob+K/Pf8eLa2OWdBpBGBwv9yUKPeYuftSYClAcXGx7swt0kOeXbuPlzcdAeBEXRMtrc6zX7uUyyYMCjiZJEo8yv0gMKrN85HRZSISkIff3MnJ+mZGDcgD4KrzBnPhmJ49UpTkEo9yXwYsNrPngEuAao23i5zdm9vLue8379PS2jP/gD1W28i3r5rMt66a1COvL8mv03I3s2eBOUChmR0A/gbIAnD3h4HlwHVAKXAK+GpPhRVJFXWNLVSeajzj+te3llFR08Ctl/TMd0+9MjL4QvHIHnltSQ2xnC2zqJP1DvzXuCUSSXGtrc6N//ctSstqzrrd0H65/K/PzUhQKkk3gU35KxIG7s47O49xsr759LJdFTWUltVw96fHM7Eo/4w/O3lo30RElDSlchfphvcPVHPbo2s+tnx4/1zuu2YKWZma4UOCoXIX6aLahma+99sNAPz6z2dTmJ9zet3Q/rkqdgmUyl2kix5ZuYttR08ycXA+n5xYSEaGrhCS5KFyl7T3xNu7WbG17Jx/bv3eKq6bMZR/uu2iHkgl0j0qd0lrLa3Oz/6wg9ysDIYX5J3Tz84Y0Z+/nDelh5KJdI/KXdLW0pU7WfL6Tqrrmvj+glncdIHOC5fwULlL6DU0t1B2ouEjy9zh8bf2MKRfDotmj+aa6UMDSifSM1TuEnpff2o9b2wr73Dd/7j+AhbMGp7gRCI9T+UuodDc0srKHeXUNbZ+ZHljSwsrt5dz46zhfGZy0UfW5WZlcO35wxIZUyRhVO4SCqt2HePPnyjpcF2GwbfmTmTiYF0RKulD5S4p7XB1HU+v3nt6Hpclt17IpCEfveQ/P6fXOZ8JI5LqVO6S0p5du58lr+8kp1cGRX1zmD1uIEV9czr/QZGQU7lLwlXUNHD/v27gVGNLt1+rtKyG8YV9eO0v53Q/mEiIqNwl4Z58Zw8rtpZx0egB3b6n55hBvblhps52EWlP5S4JteXwCX75Wilzpw7msTsvDjqOSGip3CWuahuaKTvZcMb1L30QuQPjPXMmJCqSSFpSuUtcffHhVWw+fOKs2xT1zeHisQMTlEgkPancJW7W7alk8+ET3DBzGFedN+SM27U/VVFE4k/lLnFz5+NrAfjCRSOZM2VwwGlE0ptuFSNxselQNbWNLSyaPVrFLpIEVO4SF8+v2w/AjTM1V4tIMlC5S7e9uvkov161l/GFfbh8YmHQcUQElbvEwaubjwBw6yWjA04iIh/SF6rSJS+s288Pfr+JVofGllZGFOTxXz41PuhYIhKlcpdzsr/yFA3NLfzLO3so7Jtz+g5GnxhVEHAyEWlL5S4xe6e0glsfXXP6+V9ff56O1kWSlMpdYtLQ3MIPX9xC39xe/O+bZpCdmcFnpxZ1/oMiEgiVu8RkxZYythw+wfUzhumeoyIpQOUuZ/TOzgpe2XQUgK1HIvPF/GDh9CAjiUiMYip3M5sP/BzIBB51979vt3408CRQEN3mfndfHueskkDuzgP/tpGDVXXkZkXOmJ01qoCBvbMDTiYisei03M0sE1gCXA0cANaZ2TJ339xms78GXnD3fzazacByYGwP5JUEeKe0gv/zyjZ2V9TytzfN0PnrIikolouYZgOl7r7L3RuB54CF7bZxoF/0cX/gUPwiSqKt3FHBu/uPM3/6UG6YpekERFJRLMMyI4D9bZ4fAC5pt833gVfM7JtAH+CquKSThHvsrd386o+7yOmVwcNfvijoOCLSRfGafmAR8IS7jwSuA54ys4+9tpndbWYlZlZSXl4ep7eWeFq/t5L+eVn83Z/NCDqKiHRDLOV+EBjV5vnI6LK27gJeAHD3VUAu8LEZpNx9qbsXu3txUZHOkU5Gx2oamTg4n5suGBl0FBHphliGZdYBk8xsHJFSvwW4td02+4C5wBNmdh6RcteheZJav7eSneW1Ha7be+wUF47RVAIiqa7Tcnf3ZjNbDLxM5DTHx919k5k9BJS4+zLgu8CvzOzbRL5cvdPdvSeDS9fUN7Vw+6NrqWtqOeM24wt1GzyRVBfTee7Rc9aXt1v2YJvHm4Er4htNesL//N1G6ppa+MkXZnLZhEEfW29mDOuXG0AyEYknXaGaRuoaW/jN+gMAXDtjGPk5+vhFwkp/u9PEyu3l/OTlbQD8+PMzVewiIac7MaWJVzYfYduRk8ybNoTLJ358OEZEwkWHb2misraRUQPzWHpHcdBRRCQBdOSeJg5W1TG8IC/oGCKSICr3NLG/qo6RA1TuIulCwzIh9/KmI5SdbKCytpGRA3oHHUdEEkTlHmKlZSf5+lPrTz+fPrzfWbYWkTBRuYfQI2/uZG/lKQ4drwPg6bsu4bxhfRmUnxNwMhFJFJV7yNQ3tfB3L22ld3YmvbN7MXNkfy4eN4CcXplBRxORBFK5h0BDcwv3Pv0nyk820Bqd0mfxlRP5xpyJAScTkaCo3ENg/d4qXttaRvGYAfTLy2J4QR6fnTI46FgiEiCVewq44Zd/ZOPBE2fdJjPD+JevXkzf3KwEpRKRZKZyT3L1TS1sPHiCKyYOonjMwDNuN2lIvopdRE5TuSe5f38vctOr+ecP48uXjgk4jYikCl2hmuQaWyJfkM6dqjF0EYmdyj1FZGXqoxKR2KkxktzOspqgI4hIClK5J7n66L1O++fpy1IRiZ3KPclV1jYyZUhfsnvpoxKR2Kkxkpi7U9fUQm62pg4QkXOjck9iX39qPX/cUUGmBZ1ERFKNznNPMrvKazhe10RtQzOvbjnK3KmDuWfOhKBjiUiKUbknkUPH67jyp29+ZNlfXXceEwfnB5RIRFKVyj2JbDoUmT/mvmumMH14Pwb2yVaxi0iXqNyTyKZD1QDcMHMYYwb1CTiNiKQyfaGaRE7UNZPdK0PFLiLdpnJPIjvKTjK+UMUuIt2nck8STS2trNtTyaXjBwUdRURCQOWeBFpbnQNVddQ3tTJlaN+g44hICOgL1SRw8yOrKNlbBcDgvjkBpxGRMIjpyN3M5pvZNjMrNbP7z7DNzWa22cw2mdkz8Y0ZXvVNLZTsreLS8QP5mxunccXEwqAjiUgIdHrkbmaZwBLgauAAsM7Mlrn75jbbTAL+CrjC3avMTHeWiNFPX9kGwLXnD+Mrl48NNoyIhEYsR+6zgVJ33+XujcBzwMJ223wNWOLuVQDuXhbfmOHU2uq8uOEwkwbns2j26KDjiEiIxFLuI4D9bZ4fiC5razIw2czeNrPVZja/oxcys7vNrMTMSsrLy7uWOET2V53iUHU9X71inKb0FZG4ilej9AImAXOARcCvzKyg/UbuvtTdi929uKioKE5vnboqahoAGF6QG3ASEQmbWMr9IDCqzfOR0WVtHQCWuXuTu+8GthMpezmLYzWNAAzqozNkRCS+Yin3dcAkMxtnZtnALcCydtv8jshRO2ZWSGSYZlccc4bO4mf+xAO/2wjAwPzsgNOISNh0Wu7u3gwsBl4GtgAvuPsmM3vIzBZEN3sZOGZmm4HXgfvc/VhPhU51VbWN/MeGwwztl8vXPjWO4f01LCMi8RXTRUzuvhxY3m7Zg20eO/Cd6C/pxBcfWQXAd+dNZs4UnTUqIvGnK1QT6Eh1PbsrajlYVUdhfjaf1AVLItJDVO4JdNujq9lZXgtEjtp7Zer0RxHpGSr3BNl37BQ7y2tZNHs0N10wglmj+gcdSURCTOWeIE+u2gPAwk8MZ/a4gYFmEZHw07hAgqzZfYyLxgzQfO0ikhAq9wTZXV7LzJEaihGRxFC5J4C7c6qphT7ZGgUTkcRQuSdAQ3Mr7pCXnRl0FBFJEyr3BNgVPf0xRzM/ikiCqG162P7KU7y29SgAU4f2CziNiKQLDQL3sNseXcO+ylNkGLr5tYgkjMq9h+2rPMXV04bwvflTKdLNr0UkQTQs04N2V0TG2kcU5DFxcH7AaUQknajce9A7OysAuOOyMQEnEZF0o3LvQRv2VzOwTzbjCvsEHUVE0ozG3OPI3fmL597j3X1VAJSfbOCC0QWYWcDJRCTdqNzjaN2eKn7//iGumDiIIf0id1f63CdGBJxKRNKRyj2O7nl6PQCPfLmY/Bz91opIcDTmHkeVtY3MHjdQxS4igVO5x8nxU40AjB7YO+AkIiIq97ipb2oF0LS+IpIUVO5xUtPQBEC/3KyAk4iIqNzj5unV+wB0JaqIJAWVe5xsPnQCgMlDNDmYiARP5R4Hra3O2j2VXDdjKNmas11EkoDO2euGk/VN1De1Ul0XOVNmYJ/sgBOJiESo3Ltox9GTXPOPK2n1/1x2xYTC4AKJiLShcj9H7s7a3ZW8uvkorQ73XTOFfnlZ5PbK4LNTBwcdT0QEULmfs02HTvClpasBKOidxb2fmUBGhiYGE5HkonI/RweP1wHwsy/N4vIJhSp2EUlKMZ3aYWbzzWybmZWa2f1n2e7zZuZmVhy/iMnlw7srfXpS0emZH0VEkk2n5W5mmcAS4FpgGrDIzKZ1sF1f4FvAmniHTBb/9EYpT76zh4mD8xmUr/uhikjyiuXIfTZQ6u673L0ReA5Y2MF2PwR+BNTHMV9SeeLtPdQ3tXDXJ8cFHUVE5KxiKfcRwP42zw9El51mZhcCo9z9xThmSxruzpcfW0N5TQPzzx/Gotmjg44kInJW3b6c0swygH8AvhvDtnebWYmZlZSXl3f3rROmvKaBP+6o4JJxA7nl4lFBxxER6VQs5X4QaNtoI6PLPtQXOB94w8z2AJcCyzr6UtXdl7p7sbsXFxUVdT11gu04WgPAN6+cxKxRBQGnERHpXCzlvg6YZGbjzCwbuAVY9uFKd69290J3H+vuY4HVwAJ3L+mRxAHYduQkoEnBRCR1dFru7t4MLAZeBrYAL7j7JjN7yMwW9HTAZLD96EkG9M6iMF9zx4hIaojpIiZ3Xw4sb7fswTNsO6f7sZLDC+v2s7/qFG+VVjB5SF/MdMGSiKQGXaF6BgeP1/Hf/3UDZmDArZfoDBkRSR0q9w5Un2ri5odXAbD8Lz7FecP6BZxIROTc6M4SHdhy5AQHj9cxemBvpuhLVBFJQSr3Dmw9HLll3o8+P1MTg4lISlK5d2B7WeS89hkj+wecRESka1TuHVi18xhzpw4mP0dfSYhIalK5t3O4uo7dFbVcNmFQ0FFERLpM5d7OxoOR8fYLxwwIOImISNep3Nt4d18Vv10fmQAzt1dmwGlERLpOg8pt/OMfdvDm9nIK83MY0k834xCR1KVyb6OipoErpw7m8TsvDjqKiEi3aFimjWM1jQzqo8nBRCT1qdzbqKxtZKBmfhSREFC5R1XVNtLY0kqOvkgVkRBQuRMZa7/s71cAkNNLvyUikvr0hSrw0geHqW9q5fs3TuOmC0cGHUdEpNtU7sDvNxxm4uB8vnL5WN2QQ0RCIe3HILYeOcHa3ZXcMHOYil1EQiPty/31reUALJg1POAkIiLxk7bDMo3NrXz7hfd4b99x+mRnMr4oP+hIIiJxk7ZH7nuO1fLihsP0zs7kjsvHBh1HRCSu0vbIveJkAwA/WDidyycUBpxGRCS+0q7c3Z0DVXWs31sFwJhBfQJOJCISf2lX7i9+cJjFz7wLQP+8LIb3zw04kYhI/KVduVfVNgLww8+dzwWjCnT6o4iEUtqV+4euPX8ohfmas11EwimtzpapPtXEz1fsCDqGiEiPS6tyf3tnBRU1jeRlZdI3N23/0SIiaSCtyt098t9/X3yFpvYVkVBLq3IXEUkXaVXuHxysBiBDJ8iISMjFVO5mNt/MtplZqZnd38H675jZZjPbYGYrzGxM/KN23anGZnYcPcmxmshVqeMLNY+MiIRbp98qmlkmsAS4GjgArDOzZe6+uc1m7wLF7n7KzO4Ffgx8qScCd8U9T/+Jldsjsz+OK+xDhg7dRSTkYjllZDZQ6u67AMzsOWAhcLrc3f31NtuvBm6PZ8ju2nusltljB3LH5WOYMqRv0HFERHpcLMMyI4D9bZ4fiC47k7uAlzpaYWZ3m1mJmZWUl5fHnrKbjtU0Mn1EP26YOZxJKncRSQNx/ULVzG4HioGfdLTe3Ze6e7G7FxcVFcXzrc+ouq6JmoZmBvXJTsj7iYgkg1iGZQ4Co9o8Hxld9hFmdhXwAPAZd2+IT7zuW7PrGADD+ucFnEREJHFiOXJfB0wys3Fmlg3cAixru4GZXQA8Aixw97L4x+y6HWU1AFw9fUjASUREEqfTcnf3ZmAx8DKwBXjB3TeZ2UNmtiC62U+AfOA3ZvaemS07w8sl3KHjdQzonUW/3Kygo4iIJExME6y4+3JgebtlD7Z5fFWcc8XF7Y+u4e2dFUwarPPaRSS9hHb2rPqmFt4qrWD68H58b/7UoOOIiCRUaKcfeODfNgJw2fhBfHpyYs7MERFJFqEs93f3VfHu/ioyM4zFV04MOo6ISMKFblimqaWVOx5by8mGZm67ZDQFvXV+u4ikn9CV+4otRznZ0Mzf3jSDL108qvMfEBEJodANy2w+dAKA62cMI1MThIlImgpduTuR+dr799Z57SKSvkJX7iIiEqIx91+s2MHP/rAdd8jK1HCMiKS30JT7BwerGdQnh1tnj2KCrkgVkTQXmnKva2xh9MA8vjNvStBRREQCF5ox97W7K+mdHZr/V4mIdEsoyr2ipoHGllZqGpqDjiIikhRCUe5NLa0A3Fysi5ZERCAk5f4hXbMkIhIRqnIXEZGIUJR7qwedQEQkuaT86SW/XLGDn766HYAMjcuIiAAhKPc3t5fTN7cX986ZwLxpugm2iAikeLmXn2ygZG8VIwry+MYc3ZRDRORDKT3m/vy6fQB8a+6kgJOIiCSXlC73Z9ZEyn3edA3HiIi0lbLlvruilkPV9dx+qW6lJyLSXsqW+0sbDwPwyYlFAScREUk+KVnuzS2t/Pj/bQNgzhSVu4hIeylZ7lWnmgAY0i+H3KzMgNOIiCSflCz3a3++EoBvXqmzZEREOpKS5V5R00j/vCyunzEs6CgiIkkpJcsd4M7LxzKgj86SERHpSMqVe31TS9ARRESSXkzlbmbzzWybmZWa2f0drM8xs+ej69eY2dh4B/3Qql3HeuqlRURCo9NyN7NMYAlwLTANWGRm09ptdhdQ5e4TgZ8BP4p30A81t0Tm971ak4SJiJxRLEfus4FSd9/l7o3Ac8DCdtssBJ6MPv4tMNfMemT+3brosExOr5QbURIRSZhYGnIEsL/N8wPRZR1u4+7NQDUwKB4B26usaQBgUH5OT7y8iEgoJPTw18zuNrMSMyspLy/v0msML8hj3rQhFORlxTmdiEh4xDKf+0FgVJvnI6PLOtrmgJn1AvoDH/vm092XAksBiouLu3RzvHnThzJv+tCu/KiISNqI5ch9HTDJzMaZWTZwC7Cs3TbLgK9EH38BeM3ddWdTEZGAdHrk7u7NZrYYeBnIBB53901m9hBQ4u7LgMeAp8ysFKgk8j8AEREJSEy32XP35cDydssebPO4HvhifKOJiEhX6XxCEZEQUrmLiISQyl1EJIRU7iIiIaRyFxEJIQvqdHQzKwf2dvHHC4GKOMZJBdrn9KB9Tg/d2ecx7t7pzaMDK/fuMLMSdy8OOkciaZ/Tg/Y5PSRinzUsIyISQip3EZEQStVyXxp0gABon9OD9jk99Pg+p+SYu4iInF2qHrmLiMhZJHW5J9ONuRMlhn3+jpltNrMNZrbCzMYEkTOeOtvnNtt93szczFL+zIpY9tnMbo5+1pvM7JlEZ4y3GP5sjzaz183s3eif7+uCyBkvZva4mZWZ2cYzrDcz+0X092ODmV0Y1wDunpS/iEwvvBMYD2QD7wPT2m3zDeDh6ONbgOeDzp2Aff4s0Dv6+N502Ofodn2BlcBqoDjo3An4nCcB7wIDos8HB507Afu8FLg3+ngasCfo3N3c508DFwIbz7D+OuAlwIBLgTXxfP9kPnJPqhtzJ0in++zur7v7qejT1UTujJXKYvmcAX4I/AioT2S4HhLLPn8NWOLuVQDuXpbgjPEWyz470C/6uD9wKIH54s7dVxK5v8WZLAR+7RGrgQIzGxav90/mck+qG3MnSCz73NZdRP7Pn8o63efoP1dHufuLiQzWg2L5nCcDk83sbTNbbWbzE5auZ8Syz98HbjezA0TuH/HNxEQLzLn+fT8nMd2sQ5KPmd0OFAOfCTpLTzKzDOAfgDsDjpJovYgMzcwh8q+zlWY2w92PB5qqZy0CnnD3n5rZZUTu7na+u7cGHSwVJfOR+7ncmJuz3Zg7hcSyz5jZVcADwAJ3b0hQtp7S2T73Bc4H3jCzPUTGJpel+JeqsXzOB4Bl7t7k7ruB7UTKPlXFss93AS8AuPsqIJfIHCxhFdPf965K5nJPxxtzd7rPZnYB8AiRYk/1cVjoZJ/dvdrdC919rLuPJfI9wwJ3LwkmblzE8mf7d0SO2jGzQiLDNLsSGTLOYtnnfcBcADM7j0i5lyc0ZWItA+6InjVzKVDt7ofj9upBf6PcybfN1xE5YtkJPBBd9hCRv9wQ+fB/A5QCa4HxQWdOwD7/ATgKvBf9tSzozD29z+22fYMUP1smxs/ZiAxHbQY+AG4JOnMC9nka8DaRM2neA+YFnbmb+/sscBhoIvIvsbuAe4B72nzGS6K/Hx/E+8+1rlAVEQmhZB6WERGRLlK5i4iEkMpdRCSEVO4iIiGkchcRCSGVu4hICKncRURCSOUuIhJC/x9quQjzWURLrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129fa9160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sens = []\n",
    "spec = []\n",
    "most_goodest = []\n",
    "# pred = clf.predict_proba(X_testo)[:,1]\n",
    "pred = logreg.predict_proba(X_testo)[:,1]\n",
    "for n in np.linspace(0, 1, 1001):\n",
    "    temp = 1 * (pred > n)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_testo, temp).ravel()\n",
    "    sens += [tp / (tp + fn)]\n",
    "    spec += [1 - (tn / (tn + fp))]\n",
    "    most_goodest += [tp + tn]\n",
    "# sens += [0]\n",
    "# spec += [0]\n",
    "plt.plot(spec, sens);\n",
    "plt.show()\n",
    "# plt.plot(np.linspace(0, 1, 1001), most_goodest)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13255"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf.predict_proba(X_traino)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2102"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_testo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 0.9792000000000001)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([x for x in zip(most_goodest, np.linspace(0, 1, 10001))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1984, 8, 86, 24)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = 1 * (pred > .9792)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, temp).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.001, 0.002, ..., 0.998, 0.999, 1.   ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 1, 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "5         0\n",
       "6         0\n",
       "7         0\n",
       "8         0\n",
       "9         0\n",
       "10        0\n",
       "11        0\n",
       "12        0\n",
       "13        0\n",
       "14        0\n",
       "15        0\n",
       "16        0\n",
       "17        0\n",
       "18        0\n",
       "19        0\n",
       "20        0\n",
       "21        0\n",
       "22        0\n",
       "23        0\n",
       "24        0\n",
       "25        0\n",
       "26        0\n",
       "27        0\n",
       "28        0\n",
       "29        0\n",
       "         ..\n",
       "116263    0\n",
       "116264    0\n",
       "116265    0\n",
       "116266    0\n",
       "116267    0\n",
       "116268    0\n",
       "116269    0\n",
       "116270    0\n",
       "116271    0\n",
       "116272    0\n",
       "116273    0\n",
       "116274    0\n",
       "116275    0\n",
       "116276    0\n",
       "116277    0\n",
       "116278    0\n",
       "116279    0\n",
       "116280    0\n",
       "116281    0\n",
       "116282    0\n",
       "116283    0\n",
       "116284    0\n",
       "116285    0\n",
       "116286    0\n",
       "116287    0\n",
       "116288    0\n",
       "116289    0\n",
       "116290    0\n",
       "116291    0\n",
       "116292    0\n",
       "Name: WnvPresent, Length: 116293, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.WnvPresent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(scaler.transform(test))\n",
    "submission = pd.DataFrame([[i + 1, x[0]] for i, x in enumerate(preds.tolist())], columns=sample.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>WnvPresent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.074654e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.140841e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.462343e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5.558945e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>5.558945e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4.147224e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>7.807513e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>7.877608e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>3.545267e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>3.545267e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>8.582043e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>5.587475e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2.922154e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>4.234233e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>4.234233e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116263</th>\n",
       "      <td>116264</td>\n",
       "      <td>3.831907e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116264</th>\n",
       "      <td>116265</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116265</th>\n",
       "      <td>116266</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116266</th>\n",
       "      <td>116267</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116267</th>\n",
       "      <td>116268</td>\n",
       "      <td>3.928562e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116268</th>\n",
       "      <td>116269</td>\n",
       "      <td>3.928562e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116269</th>\n",
       "      <td>116270</td>\n",
       "      <td>3.989276e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116270</th>\n",
       "      <td>116271</td>\n",
       "      <td>5.138915e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116271</th>\n",
       "      <td>116272</td>\n",
       "      <td>8.304199e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116272</th>\n",
       "      <td>116273</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116273</th>\n",
       "      <td>116274</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116274</th>\n",
       "      <td>116275</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116275</th>\n",
       "      <td>116276</td>\n",
       "      <td>6.404276e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116276</th>\n",
       "      <td>116277</td>\n",
       "      <td>6.404276e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116277</th>\n",
       "      <td>116278</td>\n",
       "      <td>7.193888e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116278</th>\n",
       "      <td>116279</td>\n",
       "      <td>1.619701e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116279</th>\n",
       "      <td>116280</td>\n",
       "      <td>2.369281e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116280</th>\n",
       "      <td>116281</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116281</th>\n",
       "      <td>116282</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116282</th>\n",
       "      <td>116283</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116283</th>\n",
       "      <td>116284</td>\n",
       "      <td>4.089076e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116284</th>\n",
       "      <td>116285</td>\n",
       "      <td>4.089076e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116285</th>\n",
       "      <td>116286</td>\n",
       "      <td>1.989256e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116286</th>\n",
       "      <td>116287</td>\n",
       "      <td>8.767130e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116287</th>\n",
       "      <td>116288</td>\n",
       "      <td>1.267679e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116288</th>\n",
       "      <td>116289</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116289</th>\n",
       "      <td>116290</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116290</th>\n",
       "      <td>116291</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116291</th>\n",
       "      <td>116292</td>\n",
       "      <td>5.056237e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116292</th>\n",
       "      <td>116293</td>\n",
       "      <td>5.056237e-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116293 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id    WnvPresent\n",
       "0            1  7.074654e-18\n",
       "1            2  2.140841e-32\n",
       "2            3  9.462343e-19\n",
       "3            4  0.000000e+00\n",
       "4            5  0.000000e+00\n",
       "5            6  0.000000e+00\n",
       "6            7  5.558945e-15\n",
       "7            8  5.558945e-15\n",
       "8            9  4.147224e-23\n",
       "9           10  7.807513e-33\n",
       "10          11  7.877608e-18\n",
       "11          12  0.000000e+00\n",
       "12          13  0.000000e+00\n",
       "13          14  0.000000e+00\n",
       "14          15  3.545267e-15\n",
       "15          16  3.545267e-15\n",
       "16          17  8.582043e-18\n",
       "17          18  5.587475e-23\n",
       "18          19  2.922154e-19\n",
       "19          20  0.000000e+00\n",
       "20          21  0.000000e+00\n",
       "21          22  0.000000e+00\n",
       "22          23  4.234233e-13\n",
       "23          24  4.234233e-13\n",
       "24          25  0.000000e+00\n",
       "25          26  0.000000e+00\n",
       "26          27  0.000000e+00\n",
       "27          28  0.000000e+00\n",
       "28          29  0.000000e+00\n",
       "29          30  0.000000e+00\n",
       "...        ...           ...\n",
       "116263  116264  3.831907e-19\n",
       "116264  116265  0.000000e+00\n",
       "116265  116266  0.000000e+00\n",
       "116266  116267  0.000000e+00\n",
       "116267  116268  3.928562e-14\n",
       "116268  116269  3.928562e-14\n",
       "116269  116270  3.989276e-04\n",
       "116270  116271  5.138915e-09\n",
       "116271  116272  8.304199e-06\n",
       "116272  116273  0.000000e+00\n",
       "116273  116274  0.000000e+00\n",
       "116274  116275  0.000000e+00\n",
       "116275  116276  6.404276e-03\n",
       "116276  116277  6.404276e-03\n",
       "116277  116278  7.193888e-16\n",
       "116278  116279  1.619701e-24\n",
       "116279  116280  2.369281e-16\n",
       "116280  116281  0.000000e+00\n",
       "116281  116282  0.000000e+00\n",
       "116282  116283  0.000000e+00\n",
       "116283  116284  4.089076e-08\n",
       "116284  116285  4.089076e-08\n",
       "116285  116286  1.989256e-35\n",
       "116286  116287  8.767130e-29\n",
       "116287  116288  1.267679e-20\n",
       "116288  116289  0.000000e+00\n",
       "116289  116290  0.000000e+00\n",
       "116290  116291  0.000000e+00\n",
       "116291  116292  5.056237e-19\n",
       "116292  116293  5.056237e-19\n",
       "\n",
       "[116293 rows x 2 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusions = [x for x in train.columns if x not in test.columns] + [x for x in test.columns if x not in train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NumMosquitos', 'WnvPresent', 'Id']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "beep = train.drop(columns=exclusions)\n",
    "boop = test.drop(columns=exclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=116293, step=1)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boop.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = train.drop(columns='WnvPresent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Block', 'Street', 'Trap', 'Latitude', 'Longitude', 'AddressAccuracy',\n",
       "       'Tmax_x', 'Tmin_x', 'Tavg_x', 'Depart_x', 'DewPoint_x', 'WetBulb_x',\n",
       "       'Cool_x', 'StnPressure_x', 'SeaLevel_x', 'Tmax_y', 'Tmin_y', 'Tavg_y',\n",
       "       'DewPoint_y', 'WetBulb_y', 'Heat_y', 'Cool_y', 'StnPressure_y',\n",
       "       'SeaLevel_y', 'temp_delta_x', 'temp_delta_y', 'israining_x',\n",
       "       'israining_y', 'sunlight', 'RH', 'isheat', 'wind_north_x',\n",
       "       'wind_east_x', 'wind_north_y', 'wind_east_y', 'avg_wind_north_x',\n",
       "       'avg_wind_east_x', 'avg_wind_north_y', 'avg_wind_east_y', 'Species_1.0',\n",
       "       'Species_2.0', 'Species_3.0', 'Species_4.0', 'Species_5.0',\n",
       "       'Species_6.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Block', 'Street', 'Trap', 'Latitude', 'Longitude', 'AddressAccuracy',\n",
       "       'Tmax_x', 'Tmin_x', 'Tavg_x', 'Depart_x', 'DewPoint_x', 'WetBulb_x',\n",
       "       'Cool_x', 'StnPressure_x', 'SeaLevel_x', 'Tmax_y', 'Tmin_y', 'Tavg_y',\n",
       "       'DewPoint_y', 'WetBulb_y', 'Heat_y', 'Cool_y', 'StnPressure_y',\n",
       "       'SeaLevel_y', 'temp_delta_x', 'temp_delta_y', 'israining_x',\n",
       "       'israining_y', 'sunlight', 'RH', 'isheat', 'wind_north_x',\n",
       "       'wind_east_x', 'wind_north_y', 'wind_east_y', 'avg_wind_north_x',\n",
       "       'avg_wind_east_x', 'avg_wind_north_y', 'avg_wind_east_y', 'Species_1.0',\n",
       "       'Species_2.0', 'Species_3.0', 'Species_4.0', 'Species_5.0',\n",
       "       'Species_6.0', 'Species_7.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Block',\n",
       " 'Street',\n",
       " 'Trap',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'AddressAccuracy',\n",
       " 'Tmax_x',\n",
       " 'Tmin_x',\n",
       " 'Tavg_x',\n",
       " 'Depart_x',\n",
       " 'DewPoint_x',\n",
       " 'WetBulb_x',\n",
       " 'Cool_x',\n",
       " 'StnPressure_x',\n",
       " 'SeaLevel_x',\n",
       " 'Tmax_y',\n",
       " 'Tmin_y',\n",
       " 'Tavg_y',\n",
       " 'DewPoint_y',\n",
       " 'WetBulb_y',\n",
       " 'Heat_y',\n",
       " 'Cool_y',\n",
       " 'StnPressure_y',\n",
       " 'SeaLevel_y',\n",
       " 'temp_delta_x',\n",
       " 'temp_delta_y',\n",
       " 'israining_x',\n",
       " 'israining_y',\n",
       " 'sunlight',\n",
       " 'RH',\n",
       " 'isheat',\n",
       " 'wind_north_x',\n",
       " 'wind_east_x',\n",
       " 'wind_north_y',\n",
       " 'wind_east_y',\n",
       " 'avg_wind_north_x',\n",
       " 'avg_wind_east_x',\n",
       " 'avg_wind_north_y',\n",
       " 'avg_wind_east_y',\n",
       " 'Species_1.0',\n",
       " 'Species_2.0',\n",
       " 'Species_3.0',\n",
       " 'Species_4.0',\n",
       " 'Species_5.0',\n",
       " 'Species_6.0']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x,y in zip(trainer.columns, test.columns) if x==y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
